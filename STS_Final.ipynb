{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae4b678",
   "metadata": {},
   "source": [
    "\n",
    "## Simulation Framework\n",
    "\n",
    "### 1. 实验目标与总体流程\n",
    "本文的 simulation 采用“**基础基线 → 预训练模型快速探索 → 阶段性训练 → 统一测试 → 鲁棒性分析**”的五阶段框架。核心目标是比较不同语义匹配模型在标准测试集与对抗式语义扰动下的性能差异，并分析模型对细粒度语义变化的敏感性与稳定性。\n",
    "\n",
    "### 2. 基础 Baseline（两种方法）\n",
    "1. **Lexical Baseline（TF-IDF）**：将句对编码为词法特征，并以线性分类/相似度计算作为下界。  \n",
    "2. **Static Embedding Baseline（静态词向量池化）**：对句子进行词向量池化（如 mean/max），再以 cosine 相似度建模语义接近程度。  \n",
    "\n",
    "该部分提供“低成本、可解释”的参照系，用于衡量后续深度模型的增益。\n",
    "\n",
    "### 3. 现有模型探索（简单测试）\n",
    "在统一输入与评估协议下，对 **BERT、ALBERT、RoBERTa、SBERT** 做快速验证（如零样本/少量训练设置），观察其在语义匹配任务上的初始表现。  \n",
    "其中，SBERT 采用双塔句向量 + cosine；BERT/ALBERT/RoBERTa 采用 cross-encoder 打分或分类头输出，形成统一可比的相似度/标签预测。\n",
    "\n",
    "### 4. 基于 BERT 的阶段性训练\n",
    "采用两阶段训练策略：  \n",
    "- **Phase A**：先在句对二分类任务（如 paraphrase）上训练，学习通用匹配能力；  \n",
    "- **Phase B**：迁移到语义相似度回归任务继续微调，使输出更贴近细粒度语义强度。  \n",
    "\n",
    "该策略用于验证“先学习句对判别，再学习相似度标定”的迁移收益。\n",
    "\n",
    "### 5. 测试集统一评测（所有模型）\n",
    "在同一测试集上报告全模型性能：  \n",
    "- 分类任务：`Accuracy`、`F1`；  \n",
    "- 回归/相似度任务：`Pearson`、`Spearman`（可附 `MAE`）。  \n",
    "\n",
    "并通过统一阈值选择策略（在验证集选阈值）保证比较公平性。\n",
    "\n",
    "### 6. 自建鲁棒性数据集与分析\n",
    "构建 stress-test 集合，覆盖 8 类关键语义扰动：  \n",
    "1) Negation（否定）  \n",
    "2) Increase/Decrease（方向变化）  \n",
    "3) Comparative Flip（比较级反转）  \n",
    "4) Role Swap（角色交换）  \n",
    "5) Numeric Change（数值变化）  \n",
    "6) Quantifier Shift（量词变化）  \n",
    "7) Modal Shift（模态变化）  \n",
    "8) Direction Swap（方向交换）\n",
    "\n",
    "评测方式为：在开发集选阈值、在测试集报告总体 `Acc/F1` 与分类型准确率；同时补充错误案例分析（高词面重叠但语义冲突），以刻画模型鲁棒性短板。\n",
    "\n",
    "### 7. 论文呈现建议\n",
    "建议在 simulation 部分给出三张核心表：  \n",
    "- **Table 1**：Baseline 与预训练模型的主结果；  \n",
    "- **Table 2**：BERT 阶段性训练前后对比；  \n",
    "- **Table 3**：8 类鲁棒性分项结果与典型错误案例。  \n",
    "\n",
    "如果你愿意，我可以下一步直接给你一版“论文风格（更正式、可投稿）”的中英文双语 simulation 小节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de31a9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.10.0 | device: mps\n"
     ]
    }
   ],
   "source": [
    "# 基础依赖与全局配置\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "SEED = 42\n",
    "DEBUG_SUBSET = True  # True: 跑通流程；False: 全量训练/评估\n",
    "MAX_DEBUG_TRAIN = 2000\n",
    "MAX_DEBUG_EVAL = 500\n",
    "\n",
    "# 训练轮数（可按机器性能调整）\n",
    "BERT_NUM_EPOCHS = 1 if DEBUG_SUBSET else 3\n",
    "BERT_STSB_NUM_EPOCHS = 1 if DEBUG_SUBSET else 3\n",
    "SBERT_NUM_EPOCHS = 1 if DEBUG_SUBSET else 2\n",
    "\n",
    "PROJET_DIR = \"/Users/jinzhuoyuan/King/Saclay/Course/HoNLP/projet\"\n",
    "MODELS_DIR = os.path.join(PROJET_DIR, \"models\")\n",
    "EMB_PATH = \"/Users/jinzhuoyuan/King/Saclay/Course/HoNLP/Devoir/4/enwiki-50k_100d.txt\"\n",
    "\n",
    "os.environ.setdefault(\"PYTORCH_ENABLE_MPS_FALLBACK\", \"1\")\n",
    "\n",
    "\n",
    "def get_best_device() -> str:\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "\n",
    "DEVICE = get_best_device()\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "pd.set_option(\"display.max_colwidth\", 120)\n",
    "\n",
    "print(\"torch:\", torch.__version__, \"| device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1112292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQP splits: 2000 500 500\n",
      "STS-B splits: 2000 500 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when is the right time to start a startup</td>\n",
       "      <td>when is it the right time to stop your startup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do presidents have to go through a security clearance check if so how would trump pass and maintain</td>\n",
       "      <td>what level of national security clearance if any did trump have to pass to be briefed by the government as a candida...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how long does it take to code a simple app</td>\n",
       "      <td>what are the best simple note taking web apps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    s1  \\\n",
       "0                                                            when is the right time to start a startup   \n",
       "1  do presidents have to go through a security clearance check if so how would trump pass and maintain   \n",
       "2                                                           how long does it take to code a simple app   \n",
       "\n",
       "                                                                                                                        s2  \\\n",
       "0                                                                           when is it the right time to stop your startup   \n",
       "1  what level of national security clearance if any did trump have to pass to be briefed by the government as a candida...   \n",
       "2                                                                            what are the best simple note taking web apps   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      1  \n",
       "2      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the brown dog is running along a grassy pathway</td>\n",
       "      <td>a brown dog is running along a grassy stretch divided by strings</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a man is playing guitar</td>\n",
       "      <td>smeone is laying down</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>by late afternoon the dow jones industrial average was up 12 81 or 0 1 percent at 9 331 77 having gained 201 points ...</td>\n",
       "      <td>in morning trading the dow jones industrial average was down 8 76 or 0 1 percent at 9 310 20 having gained 201 point...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                        s1  \\\n",
       "0                                                                          the brown dog is running along a grassy pathway   \n",
       "1                                                                                                  a man is playing guitar   \n",
       "2  by late afternoon the dow jones industrial average was up 12 81 or 0 1 percent at 9 331 77 having gained 201 points ...   \n",
       "\n",
       "                                                                                                                        s2  \\\n",
       "0                                                         a brown dog is running along a grassy stretch divided by strings   \n",
       "1                                                                                                    smeone is laying down   \n",
       "2  in morning trading the dow jones industrial average was down 8 76 or 0 1 percent at 9 310 20 having gained 201 point...   \n",
       "\n",
       "   label  \n",
       "0   0.68  \n",
       "1   0.00  \n",
       "2   0.25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. 数据加载与预处理\n",
    "_re_non_alnum = re.compile(r\"[^a-z0-9\\s]\")\n",
    "_re_ws = re.compile(r\"\\s+\")\n",
    "\n",
    "\n",
    "def normalize_text(text: str | None) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = _re_non_alnum.sub(\" \", text)\n",
    "    text = _re_ws.sub(\" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def split_80_10_10(df: pd.DataFrame, seed: int = 42) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    train_df, tmp_df = train_test_split(df, test_size=0.2, random_state=seed, shuffle=True)\n",
    "    val_df, test_df = train_test_split(tmp_df, test_size=0.5, random_state=seed, shuffle=True)\n",
    "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def to_pair_df(ds_split, task: str) -> pd.DataFrame:\n",
    "    if task == \"qqp\":\n",
    "        df = pd.DataFrame({\n",
    "            \"s1\": [normalize_text(x) for x in ds_split[\"question1\"]],\n",
    "            \"s2\": [normalize_text(x) for x in ds_split[\"question2\"]],\n",
    "            \"label\": ds_split[\"label\"],\n",
    "        })\n",
    "        df = df.dropna(subset=[\"label\"])\n",
    "        df[\"label\"] = df[\"label\"].astype(int)\n",
    "        return df\n",
    "\n",
    "    if task == \"stsb\":\n",
    "        df = pd.DataFrame({\n",
    "            \"s1\": [normalize_text(x) for x in ds_split[\"sentence1\"]],\n",
    "            \"s2\": [normalize_text(x) for x in ds_split[\"sentence2\"]],\n",
    "            \"label\": ds_split[\"label\"],\n",
    "        })\n",
    "        df = df.dropna(subset=[\"label\"])\n",
    "        df[\"label\"] = (df[\"label\"].astype(float) / 5.0).clip(0.0, 1.0)\n",
    "        return df\n",
    "\n",
    "    raise ValueError(f\"unknown task: {task}\")\n",
    "\n",
    "\n",
    "qqp_raw = load_dataset(\"glue\", \"qqp\")\n",
    "stsb_raw = load_dataset(\"glue\", \"stsb\")\n",
    "\n",
    "qqp_all = pd.concat(\n",
    "    [to_pair_df(qqp_raw[\"train\"], \"qqp\"), to_pair_df(qqp_raw[\"validation\"], \"qqp\")],\n",
    "    ignore_index=True,\n",
    ")\n",
    "stsb_all = pd.concat(\n",
    "    [to_pair_df(stsb_raw[\"train\"], \"stsb\"), to_pair_df(stsb_raw[\"validation\"], \"stsb\")],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "qqp_train, qqp_val, qqp_test = split_80_10_10(qqp_all, seed=SEED)\n",
    "stsb_train, stsb_val, stsb_test = split_80_10_10(stsb_all, seed=SEED)\n",
    "\n",
    "if DEBUG_SUBSET:\n",
    "    qqp_train = qqp_train.head(MAX_DEBUG_TRAIN)\n",
    "    qqp_val = qqp_val.head(MAX_DEBUG_EVAL)\n",
    "    qqp_test = qqp_test.head(MAX_DEBUG_EVAL)\n",
    "    stsb_train = stsb_train.head(MAX_DEBUG_TRAIN)\n",
    "    stsb_val = stsb_val.head(MAX_DEBUG_EVAL)\n",
    "    stsb_test = stsb_test.head(MAX_DEBUG_EVAL)\n",
    "\n",
    "print(\"QQP splits:\", len(qqp_train), len(qqp_val), len(qqp_test))\n",
    "print(\"STS-B splits:\", len(stsb_train), len(stsb_val), len(stsb_test))\n",
    "display(qqp_train.head(3))\n",
    "display(stsb_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ef0d1",
   "metadata": {},
   "source": [
    "## 2. Baselines: Lexical + Static Embedding\n",
    "\n",
    "- Lexical Baseline: TF-IDF + Logistic Regression (QQP), TF-IDF cosine (STS-B)\n",
    "- Static Embedding Baseline: 词向量池化 + cosine，相似度映射到 [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c510939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 实现：TF-IDF + 静态词向量池化\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def _load_word2vec(path: str, max_words: int = 50_000):\n",
    "    kv = KeyedVectors.load_word2vec_format(\n",
    "        path,\n",
    "        binary=False,\n",
    "        no_header=True,\n",
    "        limit=max_words,\n",
    "    )\n",
    "    return kv, int(kv.vector_size)\n",
    "\n",
    "\n",
    "def _sent_embedding(text: str, kv: KeyedVectors, dim: int, pooling: str = \"mean\") -> np.ndarray:\n",
    "    toks = [t for t in text.split() if t in kv]\n",
    "    if not toks:\n",
    "        return np.zeros((dim,), dtype=np.float32)\n",
    "    mat = np.stack([kv.get_vector(t) for t in toks], axis=0)\n",
    "    if pooling == \"mean\":\n",
    "        return mat.mean(axis=0)\n",
    "    if pooling == \"max\":\n",
    "        return mat.max(axis=0)\n",
    "    raise ValueError(f\"unknown pooling: {pooling}\")\n",
    "\n",
    "\n",
    "def _cosine(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    if denom == 0.0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / denom)\n",
    "\n",
    "\n",
    "def _pick_best_threshold(y_true: np.ndarray, y_score: np.ndarray) -> tuple[float, float]:\n",
    "    ts = np.linspace(0.0, 1.0, 101)\n",
    "    best_t, best_f1 = 0.5, -1.0\n",
    "    for t in ts:\n",
    "        pred = (y_score >= t).astype(int)\n",
    "        cur = f1_score(y_true, pred)\n",
    "        if cur > best_f1:\n",
    "            best_f1 = float(cur)\n",
    "            best_t = float(t)\n",
    "    return best_t, best_f1\n",
    "\n",
    "\n",
    "def train_tfidf_and_static_baselines(\n",
    "    qqp_train: pd.DataFrame,\n",
    "    qqp_val: pd.DataFrame,\n",
    "    qqp_test: pd.DataFrame,\n",
    "    stsb_train: pd.DataFrame,\n",
    "    stsb_val: pd.DataFrame,\n",
    "    stsb_test: pd.DataFrame,\n",
    "    emb_path: str = EMB_PATH,\n",
    "    max_words: int = 50_000,\n",
    "    pooling: str = \"mean\",\n",
    "):\n",
    "    # Lexical TF-IDF (QQP cosine + threshold)\n",
    "    tfidf_cls = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_features=200_000)\n",
    "    tfidf_cls.fit(pd.concat([qqp_train[\"s1\"], qqp_train[\"s2\"]], ignore_index=True).tolist())\n",
    "\n",
    "    def lexical_predict_qqp(df: pd.DataFrame) -> np.ndarray:\n",
    "        A = tfidf_cls.transform(df[\"s1\"].tolist())\n",
    "        B = tfidf_cls.transform(df[\"s2\"].tolist())\n",
    "        sims = np.array([cosine_similarity(A[i], B[i])[0, 0] for i in range(A.shape[0])], dtype=np.float32)\n",
    "        return sims.clip(0.0, 1.0)\n",
    "\n",
    "    lex_val_score = lexical_predict_qqp(qqp_val)\n",
    "    lex_test_score = lexical_predict_qqp(qqp_test)\n",
    "    lex_t, _ = _pick_best_threshold(qqp_val[\"label\"].values.astype(int), lex_val_score)\n",
    "    lex_val_pred_cls = (lex_val_score >= lex_t).astype(int)\n",
    "    lex_test_pred_cls = (lex_test_score >= lex_t).astype(int)\n",
    "    lex_qqp_metrics = {\n",
    "        \"qqp_val_acc\": float(accuracy_score(qqp_val[\"label\"], lex_val_pred_cls)),\n",
    "        \"qqp_val_f1\": float(f1_score(qqp_val[\"label\"], lex_val_pred_cls)),\n",
    "        \"qqp_test_acc\": float(accuracy_score(qqp_test[\"label\"], lex_test_pred_cls)),\n",
    "        \"qqp_test_f1\": float(f1_score(qqp_test[\"label\"], lex_test_pred_cls)),\n",
    "        \"threshold\": float(lex_t),\n",
    "    }\n",
    "\n",
    "    # Lexical TF-IDF (STS-B cosine)\n",
    "    tfidf_sts = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_features=200_000)\n",
    "    tfidf_sts.fit(pd.concat([stsb_train[\"s1\"], stsb_train[\"s2\"]], ignore_index=True).tolist())\n",
    "\n",
    "    def lexical_predict_stsb(df: pd.DataFrame) -> np.ndarray:\n",
    "        A = tfidf_sts.transform(df[\"s1\"].tolist())\n",
    "        B = tfidf_sts.transform(df[\"s2\"].tolist())\n",
    "        sims = np.array([cosine_similarity(A[i], B[i])[0, 0] for i in range(A.shape[0])], dtype=np.float32)\n",
    "        return sims.clip(0.0, 1.0)\n",
    "\n",
    "    lex_val_pred_sts = lexical_predict_stsb(stsb_val)\n",
    "    lex_test_pred_sts = lexical_predict_stsb(stsb_test)\n",
    "    lex_stsb_metrics = {\n",
    "        \"stsb_val_pearson\": float(pearsonr(stsb_val[\"label\"].values, lex_val_pred_sts).statistic),\n",
    "        \"stsb_val_spearman\": float(spearmanr(stsb_val[\"label\"].values, lex_val_pred_sts).statistic),\n",
    "        \"stsb_test_pearson\": float(pearsonr(stsb_test[\"label\"].values, lex_test_pred_sts).statistic),\n",
    "        \"stsb_test_spearman\": float(spearmanr(stsb_test[\"label\"].values, lex_test_pred_sts).statistic),\n",
    "    }\n",
    "\n",
    "    # Static Embedding baseline (Word2Vec format)\n",
    "    kv, dim = _load_word2vec(emb_path, max_words=max_words)\n",
    "\n",
    "    def _static_cosine_scores(df: pd.DataFrame) -> np.ndarray:\n",
    "        scores = np.zeros((len(df),), dtype=np.float32)\n",
    "        for i, (s1, s2) in enumerate(zip(df[\"s1\"].tolist(), df[\"s2\"].tolist())):\n",
    "            e1 = _sent_embedding(s1, kv, dim, pooling=pooling)\n",
    "            e2 = _sent_embedding(s2, kv, dim, pooling=pooling)\n",
    "            scores[i] = (_cosine(e1, e2) + 1.0) / 2.0\n",
    "        return scores.clip(0.0, 1.0)\n",
    "\n",
    "    static_stsb_val = _static_cosine_scores(stsb_val)\n",
    "    static_stsb_test = _static_cosine_scores(stsb_test)\n",
    "    static_stsb_metrics = {\n",
    "        \"stsb_val_pearson\": float(pearsonr(stsb_val[\"label\"].values, static_stsb_val).statistic),\n",
    "        \"stsb_val_spearman\": float(spearmanr(stsb_val[\"label\"].values, static_stsb_val).statistic),\n",
    "        \"stsb_test_pearson\": float(pearsonr(stsb_test[\"label\"].values, static_stsb_test).statistic),\n",
    "        \"stsb_test_spearman\": float(spearmanr(stsb_test[\"label\"].values, static_stsb_test).statistic),\n",
    "    }\n",
    "\n",
    "    static_val_score = _static_cosine_scores(qqp_val)\n",
    "    static_test_score = _static_cosine_scores(qqp_test)\n",
    "    static_t, _ = _pick_best_threshold(qqp_val[\"label\"].values.astype(int), static_val_score)\n",
    "    static_val_pred = (static_val_score >= static_t).astype(int)\n",
    "    static_test_pred = (static_test_score >= static_t).astype(int)\n",
    "    static_qqp_metrics = {\n",
    "        \"qqp_val_acc\": float(accuracy_score(qqp_val[\"label\"], static_val_pred)),\n",
    "        \"qqp_val_f1\": float(f1_score(qqp_val[\"label\"], static_val_pred)),\n",
    "        \"qqp_test_acc\": float(accuracy_score(qqp_test[\"label\"], static_test_pred)),\n",
    "        \"qqp_test_f1\": float(f1_score(qqp_test[\"label\"], static_test_pred)),\n",
    "        \"threshold\": float(static_t),\n",
    "    }\n",
    "\n",
    "    def static_predict_qqp(df: pd.DataFrame) -> np.ndarray:\n",
    "        return _static_cosine_scores(df)\n",
    "\n",
    "    def static_predict_stsb(df: pd.DataFrame) -> np.ndarray:\n",
    "        return _static_cosine_scores(df)\n",
    "\n",
    "    return {\n",
    "        \"lexical\": {\n",
    "            \"qqp_metrics\": lex_qqp_metrics,\n",
    "            \"stsb_metrics\": lex_stsb_metrics,\n",
    "            \"predict_qqp\": lexical_predict_qqp,\n",
    "            \"predict_stsb\": lexical_predict_stsb,\n",
    "            \"stsb_val_pred\": lex_val_pred_sts,\n",
    "            \"stsb_test_pred\": lex_test_pred_sts,\n",
    "        },\n",
    "        \"static\": {\n",
    "            \"qqp_metrics\": static_qqp_metrics,\n",
    "            \"stsb_metrics\": static_stsb_metrics,\n",
    "            \"predict_qqp\": static_predict_qqp,\n",
    "            \"predict_stsb\": static_predict_stsb,\n",
    "            \"stsb_val_pred\": static_stsb_val,\n",
    "            \"stsb_test_pred\": static_stsb_test,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f86e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical metrics: {'qqp_val_acc': 0.636, 'qqp_val_f1': 0.6726618705035972, 'qqp_test_acc': 0.604, 'qqp_test_f1': 0.611764705882353, 'threshold': 0.24, 'stsb_val_pearson': 0.6378415042480152, 'stsb_val_spearman': 0.6196225048578498, 'stsb_test_pearson': 0.5649861286035803, 'stsb_test_spearman': 0.5581035202027839}\n",
      "Static embed metrics: {'qqp_val_acc': 0.632, 'qqp_val_f1': 0.642023346303502, 'qqp_test_acc': 0.634, 'qqp_test_f1': 0.6163522012578616, 'threshold': 0.96, 'stsb_val_pearson': 0.6134472130305588, 'stsb_val_spearman': 0.6238302416623481, 'stsb_test_pearson': 0.6351538419133075, 'stsb_test_spearman': 0.6277128213767955}\n"
     ]
    }
   ],
   "source": [
    "baseline_bundle = train_tfidf_and_static_baselines(\n",
    "    qqp_train=qqp_train,\n",
    "    qqp_val=qqp_val,\n",
    "    qqp_test=qqp_test,\n",
    "    stsb_train=stsb_train,\n",
    "    stsb_val=stsb_val,\n",
    "    stsb_test=stsb_test,\n",
    "    emb_path=EMB_PATH,\n",
    "    max_words=50_000,\n",
    "    pooling=\"mean\",\n",
    ")\n",
    "\n",
    "lex_qqp_metrics = baseline_bundle[\"lexical\"][\"qqp_metrics\"]\n",
    "lex_stsb_metrics = baseline_bundle[\"lexical\"][\"stsb_metrics\"]\n",
    "static_qqp_metrics = baseline_bundle[\"static\"][\"qqp_metrics\"]\n",
    "static_stsb_metrics = baseline_bundle[\"static\"][\"stsb_metrics\"]\n",
    "\n",
    "lexical_predict_qqp = baseline_bundle[\"lexical\"][\"predict_qqp\"]\n",
    "lexical_predict_stsb = baseline_bundle[\"lexical\"][\"predict_stsb\"]\n",
    "static_predict_qqp = baseline_bundle[\"static\"][\"predict_qqp\"]\n",
    "static_predict_stsb = baseline_bundle[\"static\"][\"predict_stsb\"]\n",
    "\n",
    "lex_stsb_test_pred = baseline_bundle[\"lexical\"][\"stsb_test_pred\"]\n",
    "static_stsb_test_pred = baseline_bundle[\"static\"][\"stsb_test_pred\"]\n",
    "\n",
    "print(\"Lexical metrics:\", {**lex_qqp_metrics, **lex_stsb_metrics})\n",
    "print(\"Static embed metrics:\", {**static_qqp_metrics, **static_stsb_metrics})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd080eab",
   "metadata": {},
   "source": [
    "## 3. 预训练模型快速探索（Zero-shot）\n",
    "\n",
    "在统一输入协议下，快速对比 BERT / SBERT 的初始表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75570918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258598f3e40f4d8b82c8499d11d2c1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "classifier.weight                          | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296c5eb5e1d343fdbd8e7c53cc921bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "classifier.weight                          | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450cf171e0c2409cb4dd643dc709a88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f92f0d01dd0478f8165c99ba2e5bb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5eb2612b89442eb93bc65c986c57518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93f7a47bb33472587cb4952d642509c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6172d8e50ad4a04a3654a9b2bb4d73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed934e35d3c4fbbb509e99c6904ad14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AlbertForSequenceClassification LOAD REPORT from: albert-base-v2\n",
      "Key                          | Status     | \n",
      "-----------------------------+------------+-\n",
      "predictions.decoder.bias     | UNEXPECTED | \n",
      "predictions.dense.weight     | UNEXPECTED | \n",
      "predictions.dense.bias       | UNEXPECTED | \n",
      "predictions.LayerNorm.weight | UNEXPECTED | \n",
      "predictions.LayerNorm.bias   | UNEXPECTED | \n",
      "predictions.bias             | UNEXPECTED | \n",
      "classifier.weight            | MISSING    | \n",
      "classifier.bias              | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9d1d93d2f64257bd0cad0effbc04e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AlbertForSequenceClassification LOAD REPORT from: albert-base-v2\n",
      "Key                          | Status     | \n",
      "-----------------------------+------------+-\n",
      "predictions.decoder.bias     | UNEXPECTED | \n",
      "predictions.dense.weight     | UNEXPECTED | \n",
      "predictions.dense.bias       | UNEXPECTED | \n",
      "predictions.LayerNorm.weight | UNEXPECTED | \n",
      "predictions.LayerNorm.bias   | UNEXPECTED | \n",
      "predictions.bias             | UNEXPECTED | \n",
      "classifier.weight            | MISSING    | \n",
      "classifier.bias              | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3822ba85d7ba45a7940afca6f58cf298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab653510bf0b4e0b864a3f5af1d7c65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee1094070b84ae782a7c710c2c19435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f760bcc3ac874cab99545368e3589a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737f7846344c420285ef094008ba2bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa03103d31434c768661bb1861abe5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d015dc27174f61a654f93fec59d3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassification LOAD REPORT from: roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "classifier.dense.weight         | MISSING    | \n",
      "classifier.out_proj.weight      | MISSING    | \n",
      "classifier.dense.bias           | MISSING    | \n",
      "classifier.out_proj.bias        | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb94ce8734e4ee7ae701268937b32b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassification LOAD REPORT from: roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "classifier.dense.weight         | MISSING    | \n",
      "classifier.out_proj.weight      | MISSING    | \n",
      "classifier.dense.bias           | MISSING    | \n",
      "classifier.out_proj.bias        | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT zero-shot (random head) QQP: {'model': 'bert-base-uncased', 'qqp_val_acc': 0.43, 'qqp_val_f1': 0.5802650957290133, 'qqp_test_acc': 0.376, 'qqp_test_f1': 0.5343283582089552}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457dd5371f804f809f30cb7a1069cfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ab0e2f57f043cb8d227064c6aa605f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7590e8a69b5417cad2294cad7856596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ebc6f057c843ba92c8cdf1256ebd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1bcf14bc9648f2b1cf0555a1cedac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c02acbf477b4c84a4c47d4832394e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707a592778dd41389f4f5ece2b420e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec1c489dd37488f84c12a705e0b578a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5de1c9a6ba45e9814fe54644c3a336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fbf40e6b8647969ab634ee38c29bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf180b2a03d4ef18a93ab7d668d355e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33275401a98e4215a72fde1f321f31ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9b53a810c54ebd9c06bf1c3825b13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239d52e8cce04442921b321258a8101c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4c2933998b46b899c8d65318bd7b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bafefaf8e0413c8a465788d20ee00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9474d800902b4080b8add778a2fa540f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8017f2707a462b87b976fd3b1fe8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202c9eeab78d445294ffbb4d361c51a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8653d287104349bd5e9752aba3a928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac86a67c0184dc49d0abecd4ad3c201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0408e486821e4b98ba65d8773e0424a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17020b19725f4d7badc1378f8d46f2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8b0a1f97ff4131941510414a9ae190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70a05ec07fc44659d78895721398441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bbf237b9c64586a2fe000d5c87c497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d06565317d1482381a1f05368189998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3099f3b3b2d04dedb5aa96e00eb8a94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946f52f44ea8450cacd9ba6c7ba87e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ce2d2ea56e47bb8a65ab2435728e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e106f4ebe2f441689c29b63d0ee427bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2236fa0347406886abcae6ad895b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047715ad156649fc8356171b6e8b5bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac280feadd7448ee8b32aaca94e33a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT zero-shot STS-B: {'model': 'sentence-transformers/all-MiniLM-L6-v2', 'stsb_val_pearson': 0.8408758100036464, 'stsb_val_spearman': 0.8198952084381534, 'stsb_test_pearson': 0.8656866930684459, 'stsb_test_spearman': 0.8385417477204856}\n",
      "SBERT zero-shot QQP (thresholded): {'model': 'sentence-transformers/all-MiniLM-L6-v2', 'qqp_val_acc': 0.778, 'qqp_val_f1': 0.7692307692307693, 'qqp_test_acc': 0.736, 'qqp_test_f1': 0.7130434782608696, 'threshold': 0.84}\n",
      "\n",
      "Zero-shot QQP comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>qqp_val_acc</th>\n",
       "      <th>qqp_val_f1</th>\n",
       "      <th>qqp_test_acc</th>\n",
       "      <th>qqp_test_f1</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.753316</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence-transformers/paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.719486</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.713043</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.580265</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.534328</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.258741</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.565280</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model  qqp_val_acc  qqp_val_f1  \\\n",
       "0        sentence-transformers/all-mpnet-base-v2        0.820    0.780488   \n",
       "1  sentence-transformers/paraphrase-MiniLM-L6-v2        0.778    0.769231   \n",
       "2         sentence-transformers/all-MiniLM-L6-v2        0.778    0.769231   \n",
       "3                              bert-base-uncased        0.430    0.580265   \n",
       "4                                 albert-base-v2        0.576    0.258741   \n",
       "5                                   roberta-base        0.394    0.565280   \n",
       "\n",
       "   qqp_test_acc  qqp_test_f1  threshold  \n",
       "0         0.814     0.753316       0.89  \n",
       "1         0.738     0.719486       0.85  \n",
       "2         0.736     0.713043       0.84  \n",
       "3         0.376     0.534328        NaN  \n",
       "4         0.644     0.011111        NaN  \n",
       "5         0.642     0.000000        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zero-shot STS-B comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>stsb_val_pearson</th>\n",
       "      <th>stsb_val_spearman</th>\n",
       "      <th>stsb_test_pearson</th>\n",
       "      <th>stsb_test_spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.819895</td>\n",
       "      <td>0.865687</td>\n",
       "      <td>0.838542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>0.869383</td>\n",
       "      <td>0.852568</td>\n",
       "      <td>0.865659</td>\n",
       "      <td>0.838948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence-transformers/paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>0.851478</td>\n",
       "      <td>0.829636</td>\n",
       "      <td>0.863941</td>\n",
       "      <td>0.841344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model  stsb_val_pearson  \\\n",
       "0         sentence-transformers/all-MiniLM-L6-v2          0.840876   \n",
       "1        sentence-transformers/all-mpnet-base-v2          0.869383   \n",
       "2  sentence-transformers/paraphrase-MiniLM-L6-v2          0.851478   \n",
       "\n",
       "   stsb_val_spearman  stsb_test_pearson  stsb_test_spearman  \n",
       "0           0.819895           0.865687            0.838542  \n",
       "1           0.852568           0.865659            0.838948  \n",
       "2           0.829636           0.863941            0.841344  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Zero-shot BERT / SBERT (multi-model comparison)\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cross-encoder models (classification head is random in zero-shot)\n",
    "BERT_ZS_MODELS = [\n",
    "    \"bert-base-uncased\",\n",
    "    \"albert-base-v2\",\n",
    "    \"roberta-base\",\n",
    "]\n",
    "\n",
    "# Bi-encoder sentence-transformers (cosine similarity)\n",
    "SBERT_ZS_MODELS = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "]\n",
    "\n",
    "\n",
    "def bert_zeroshot_predict_labels(model_name: str, df: pd.DataFrame, batch_size: int = 32) -> np.ndarray:\n",
    "    tok = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i : i + batch_size]\n",
    "        enc = tok(\n",
    "            batch[\"s1\"].tolist(),\n",
    "            batch[\"s2\"].tolist(),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "        with torch.no_grad():\n",
    "            logits = model(**enc).logits\n",
    "            preds.append(torch.argmax(logits, dim=-1).detach().cpu().numpy())\n",
    "    return np.concatenate(preds, axis=0)\n",
    "\n",
    "\n",
    "def sbert_zeroshot_scores(model_name: str, df: pd.DataFrame, batch_size: int = 64) -> np.ndarray:\n",
    "    sbert = SentenceTransformer(model_name, device=DEVICE)\n",
    "    emb1 = sbert.encode(df[\"s1\"].tolist(), batch_size=batch_size, normalize_embeddings=True, show_progress_bar=False)\n",
    "    emb2 = sbert.encode(df[\"s2\"].tolist(), batch_size=batch_size, normalize_embeddings=True, show_progress_bar=False)\n",
    "    scores = (emb1 * emb2).sum(axis=1)\n",
    "    return ((scores + 1.0) / 2.0).clip(0.0, 1.0).astype(np.float32)\n",
    "\n",
    "\n",
    "qqp_rows = []\n",
    "stsb_rows = []\n",
    "\n",
    "# --- Cross-encoder zero-shot on QQP ---\n",
    "for model_name in BERT_ZS_MODELS:\n",
    "    val_pred = bert_zeroshot_predict_labels(model_name, qqp_val, batch_size=32)\n",
    "    test_pred = bert_zeroshot_predict_labels(model_name, qqp_test, batch_size=32)\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": model_name,\n",
    "        \"qqp_val_acc\": float(accuracy_score(qqp_val[\"label\"].values, val_pred)),\n",
    "        \"qqp_val_f1\": float(f1_score(qqp_val[\"label\"].values, val_pred)),\n",
    "        \"qqp_test_acc\": float(accuracy_score(qqp_test[\"label\"].values, test_pred)),\n",
    "        \"qqp_test_f1\": float(f1_score(qqp_test[\"label\"].values, test_pred)),\n",
    "    }\n",
    "    qqp_rows.append(metrics)\n",
    "\n",
    "# Keep the original single-model metrics for downstream summary\n",
    "bert_qqp_zeroshot_metrics = next((r for r in qqp_rows if r[\"model\"] == \"bert-base-uncased\"), {})\n",
    "print(\"BERT zero-shot (random head) QQP:\", bert_qqp_zeroshot_metrics)\n",
    "\n",
    "# --- SBERT zero-shot on STS-B + QQP (thresholded) ---\n",
    "for model_name in SBERT_ZS_MODELS:\n",
    "    stsb_val_scores = sbert_zeroshot_scores(model_name, stsb_val)\n",
    "    stsb_test_scores = sbert_zeroshot_scores(model_name, stsb_test)\n",
    "\n",
    "    stsb_metrics = {\n",
    "        \"model\": model_name,\n",
    "        \"stsb_val_pearson\": float(pearsonr(stsb_val[\"label\"].values, stsb_val_scores).statistic),\n",
    "        \"stsb_val_spearman\": float(spearmanr(stsb_val[\"label\"].values, stsb_val_scores).statistic),\n",
    "        \"stsb_test_pearson\": float(pearsonr(stsb_test[\"label\"].values, stsb_test_scores).statistic),\n",
    "        \"stsb_test_spearman\": float(spearmanr(stsb_test[\"label\"].values, stsb_test_scores).statistic),\n",
    "    }\n",
    "    stsb_rows.append(stsb_metrics)\n",
    "\n",
    "    qqp_val_scores = sbert_zeroshot_scores(model_name, qqp_val)\n",
    "    qqp_test_scores = sbert_zeroshot_scores(model_name, qqp_test)\n",
    "\n",
    "    thresholds = np.linspace(0.0, 1.0, 101)\n",
    "    best_t = 0.5\n",
    "    best_f1 = -1.0\n",
    "    y_val = qqp_val[\"label\"].values.astype(int)\n",
    "    for t in thresholds:\n",
    "        pred = (qqp_val_scores >= t).astype(int)\n",
    "        f = f1_score(y_val, pred)\n",
    "        if f > best_f1:\n",
    "            best_f1 = float(f)\n",
    "            best_t = float(t)\n",
    "\n",
    "    y_test = qqp_test[\"label\"].values.astype(int)\n",
    "    qqp_val_pred = (qqp_val_scores >= best_t).astype(int)\n",
    "    qqp_test_pred = (qqp_test_scores >= best_t).astype(int)\n",
    "\n",
    "    qqp_rows.append({\n",
    "        \"model\": model_name,\n",
    "        \"qqp_val_acc\": float(accuracy_score(y_val, qqp_val_pred)),\n",
    "        \"qqp_val_f1\": float(f1_score(y_val, qqp_val_pred)),\n",
    "        \"qqp_test_acc\": float(accuracy_score(y_test, qqp_test_pred)),\n",
    "        \"qqp_test_f1\": float(f1_score(y_test, qqp_test_pred)),\n",
    "        \"threshold\": best_t,\n",
    "    })\n",
    "\n",
    "# Keep the original single-model metrics for downstream summary\n",
    "sbert_stsb_zeroshot_metrics = next((r for r in stsb_rows if r[\"model\"] == \"sentence-transformers/all-MiniLM-L6-v2\"), {})\n",
    "sbert_qqp_zeroshot_metrics = next((r for r in qqp_rows if r[\"model\"] == \"sentence-transformers/all-MiniLM-L6-v2\"), {})\n",
    "print(\"SBERT zero-shot STS-B:\", sbert_stsb_zeroshot_metrics)\n",
    "print(\"SBERT zero-shot QQP (thresholded):\", sbert_qqp_zeroshot_metrics)\n",
    "\n",
    "# --- Comparison tables ---\n",
    "qqp_zero_df = pd.DataFrame(qqp_rows)\n",
    "qqp_zero_df = qqp_zero_df.sort_values([\"qqp_test_f1\", \"qqp_test_acc\"], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "stsb_zero_df = pd.DataFrame(stsb_rows)\n",
    "stsb_zero_df = stsb_zero_df.sort_values([\"stsb_test_pearson\", \"stsb_test_spearman\"], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nZero-shot QQP comparison:\")\n",
    "display(qqp_zero_df)\n",
    "\n",
    "print(\"\\nZero-shot STS-B comparison:\")\n",
    "display(stsb_zero_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3750a82",
   "metadata": {},
   "source": [
    "## 4. 阶段性训练（BERT）\n",
    "\n",
    "- Phase A: QQP 二分类（Cross-Encoder）\n",
    "- Phase B: QQP → STS-B 回归迁移\n",
    "- 对照：直接在 STS-B 上训练（无 QQP 迁移）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25018198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 直接训练 STS-B（Cross-Encoder Regression）\n",
    "import inspect\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "print(\"transformers version:\", transformers.__version__)\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "print(\"BERT_STSB_NUM_EPOCHS:\", BERT_STSB_NUM_EPOCHS)\n",
    "\n",
    "bert_stsb_tok = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def tokenize_stsb_direct(batch):\n",
    "    return bert_stsb_tok(batch[\"s1\"], batch[\"s2\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "\n",
    "def df_to_hf_reg_direct(df: pd.DataFrame):\n",
    "    from datasets import Dataset\n",
    "\n",
    "    ds = Dataset.from_pandas(df[[\"s1\", \"s2\", \"label\"]], preserve_index=False)\n",
    "    ds = ds.map(tokenize_stsb_direct, batched=True).rename_column(\"label\", \"labels\")\n",
    "    cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "    if \"token_type_ids\" in ds.column_names:\n",
    "        cols.insert(2, \"token_type_ids\")\n",
    "    ds.set_format(type=\"torch\", columns=cols)\n",
    "    return ds\n",
    "\n",
    "\n",
    "stsb_train_ds_direct = df_to_hf_reg_direct(stsb_train)\n",
    "stsb_val_ds_direct = df_to_hf_reg_direct(stsb_val)\n",
    "stsb_test_ds_direct = df_to_hf_reg_direct(stsb_test)\n",
    "\n",
    "bert_stsb_direct = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=1)\n",
    "bert_stsb_direct.config.problem_type = \"regression\"\n",
    "\n",
    "\n",
    "def compute_stsb_reg_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.asarray(preds).reshape(-1)\n",
    "    labels = np.asarray(labels).reshape(-1)\n",
    "    preds = np.clip(preds, 0.0, 1.0)\n",
    "    return {\n",
    "        \"pearson\": float(pearsonr(labels, preds).statistic),\n",
    "        \"spearman\": float(spearmanr(labels, preds).statistic),\n",
    "    }\n",
    "\n",
    "\n",
    "ta_sig = inspect.signature(TrainingArguments)\n",
    "ta_kwargs = dict(\n",
    "    output_dir=os.path.join(MODELS_DIR, \"bert_stsb_direct\"),\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=BERT_STSB_NUM_EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=50,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "if \"evaluation_strategy\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"evaluation_strategy\"] = \"epoch\"\n",
    "elif \"eval_strategy\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"eval_strategy\"] = \"epoch\"\n",
    "\n",
    "if \"report_to\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"report_to\"] = \"none\"\n",
    "\n",
    "if \"dataloader_pin_memory\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"dataloader_pin_memory\"] = False\n",
    "\n",
    "if \"use_mps_device\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"use_mps_device\"] = (DEVICE == \"mps\")\n",
    "\n",
    "bert_stsb_direct_args = TrainingArguments(**ta_kwargs)\n",
    "\n",
    "tr_sig = inspect.signature(Trainer)\n",
    "trainer_kwargs = dict(\n",
    "    model=bert_stsb_direct,\n",
    "    args=bert_stsb_direct_args,\n",
    "    train_dataset=stsb_train_ds_direct,\n",
    "    eval_dataset=stsb_val_ds_direct,\n",
    "    compute_metrics=compute_stsb_reg_metrics,\n",
    ")\n",
    "if \"tokenizer\" in tr_sig.parameters:\n",
    "    trainer_kwargs[\"tokenizer\"] = bert_stsb_tok\n",
    "elif \"processing_class\" in tr_sig.parameters:\n",
    "    trainer_kwargs[\"processing_class\"] = bert_stsb_tok\n",
    "\n",
    "bert_stsb_direct_trainer = Trainer(**trainer_kwargs)\n",
    "\n",
    "bert_stsb_direct_trainer.train()\n",
    "\n",
    "val_eval = bert_stsb_direct_trainer.evaluate(stsb_val_ds_direct)\n",
    "test_eval = bert_stsb_direct_trainer.evaluate(stsb_test_ds_direct)\n",
    "\n",
    "_val_pred = bert_stsb_direct_trainer.predict(stsb_val_ds_direct).predictions.reshape(-1)\n",
    "_test_pred = bert_stsb_direct_trainer.predict(stsb_test_ds_direct).predictions.reshape(-1)\n",
    "bert_stsb_direct_val_pred = np.clip(_val_pred, 0.0, 1.0).astype(np.float32)\n",
    "bert_stsb_direct_test_pred = np.clip(_test_pred, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "bert_stsb_direct_metrics = {\n",
    "    \"stsb_val_pearson\": float(val_eval.get(\"eval_pearson\", np.nan)),\n",
    "    \"stsb_val_spearman\": float(val_eval.get(\"eval_spearman\", np.nan)),\n",
    "    \"stsb_test_pearson\": float(test_eval.get(\"eval_pearson\", np.nan)),\n",
    "    \"stsb_test_spearman\": float(test_eval.get(\"eval_spearman\", np.nan)),\n",
    "}\n",
    "print(\"BERT direct STS-B:\", bert_stsb_direct_metrics)\n",
    "\n",
    "bert_stsb_direct_trainer.save_model(bert_stsb_direct_args.output_dir)\n",
    "bert_stsb_tok.save_pretrained(bert_stsb_direct_args.output_dir)\n",
    "print(\"Saved BERT direct STS-B model to:\", bert_stsb_direct_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ee88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase A: BERT Cross-Encoder 微调 (QQP classification)\n",
    "import evaluate\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "print(\"BERT_NUM_EPOCHS:\", BERT_NUM_EPOCHS)\n",
    "\n",
    "qqp_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def tokenize_qqp(batch):\n",
    "    return qqp_tokenizer(batch[\"s1\"], batch[\"s2\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "\n",
    "def df_to_hf_qqp(df: pd.DataFrame):\n",
    "    from datasets import Dataset\n",
    "\n",
    "    ds = Dataset.from_pandas(df[[\"s1\", \"s2\", \"label\"]], preserve_index=False)\n",
    "    ds = ds.map(tokenize_qqp, batched=True).rename_column(\"label\", \"labels\")\n",
    "    cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "    if \"token_type_ids\" in ds.column_names:\n",
    "        cols.insert(2, \"token_type_ids\")\n",
    "    ds.set_format(type=\"torch\", columns=cols)\n",
    "    return ds\n",
    "\n",
    "\n",
    "qqp_train_ds = df_to_hf_qqp(qqp_train)\n",
    "qqp_val_ds = df_to_hf_qqp(qqp_val)\n",
    "qqp_test_ds = df_to_hf_qqp(qqp_test)\n",
    "\n",
    "bert_qqp = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "f1_eval = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_qqp_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1_eval.compute(predictions=preds, references=labels)[\"f1\"],\n",
    "    }\n",
    "\n",
    "\n",
    "ta_sig = inspect.signature(TrainingArguments)\n",
    "ta_kwargs = dict(\n",
    "    output_dir=os.path.join(MODELS_DIR, \"bert_qqp\"),\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=BERT_NUM_EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=50,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "if \"evaluation_strategy\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"evaluation_strategy\"] = \"epoch\"\n",
    "elif \"eval_strategy\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"eval_strategy\"] = \"epoch\"\n",
    "\n",
    "if \"report_to\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"report_to\"] = \"none\"\n",
    "\n",
    "if \"dataloader_pin_memory\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"dataloader_pin_memory\"] = False\n",
    "\n",
    "if \"use_mps_device\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"use_mps_device\"] = (DEVICE == \"mps\")\n",
    "\n",
    "args = TrainingArguments(**ta_kwargs)\n",
    "\n",
    "tr_sig = inspect.signature(Trainer)\n",
    "trainer_kwargs = dict(\n",
    "    model=bert_qqp,\n",
    "    args=args,\n",
    "    train_dataset=qqp_train_ds,\n",
    "    eval_dataset=qqp_val_ds,\n",
    "    compute_metrics=compute_qqp_metrics,\n",
    ")\n",
    "if \"tokenizer\" in tr_sig.parameters:\n",
    "    trainer_kwargs[\"tokenizer\"] = qqp_tokenizer\n",
    "elif \"processing_class\" in tr_sig.parameters:\n",
    "    trainer_kwargs[\"processing_class\"] = qqp_tokenizer\n",
    "\n",
    "qqp_trainer = Trainer(**trainer_kwargs)\n",
    "\n",
    "qqp_trainer.train()\n",
    "\n",
    "bert_qqp_val = qqp_trainer.evaluate(qqp_val_ds)\n",
    "bert_qqp_test = qqp_trainer.evaluate(qqp_test_ds)\n",
    "\n",
    "bert_qqp_metrics = {\n",
    "    \"qqp_val_acc\": float(bert_qqp_val[\"eval_accuracy\"]),\n",
    "    \"qqp_val_f1\": float(bert_qqp_val[\"eval_f1\"]),\n",
    "    \"qqp_test_acc\": float(bert_qqp_test[\"eval_accuracy\"]),\n",
    "    \"qqp_test_f1\": float(bert_qqp_test[\"eval_f1\"]),\n",
    "}\n",
    "print(\"BERT QQP metrics:\", bert_qqp_metrics)\n",
    "\n",
    "qqp_trainer.save_model(args.output_dir)\n",
    "qqp_tokenizer.save_pretrained(args.output_dir)\n",
    "print(\"Saved QQP fine-tuned model to:\", args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d144657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase B: QQP → STS-B 回归迁移\n",
    "import torch.nn as nn\n",
    "\n",
    "QQP_MODEL_DIR = os.path.join(MODELS_DIR, \"bert_qqp\")\n",
    "STSB_MODEL_DIR = os.path.join(MODELS_DIR, \"bert_qqp_to_stsb_reg\")\n",
    "\n",
    "if not os.path.exists(QQP_MODEL_DIR):\n",
    "    raise FileNotFoundError(\n",
    "        f\"QQP_MODEL_DIR not found: {QQP_MODEL_DIR}. \"\n",
    "        \"请先运行 QQP 微调单元，或把 QQP_MODEL_DIR 改成你的 checkpoint 目录。\"\n",
    "    )\n",
    "\n",
    "stsb_tokenizer = qqp_tokenizer if \"qqp_tokenizer\" in globals() else AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def tokenize_stsb(batch):\n",
    "    return stsb_tokenizer(batch[\"s1\"], batch[\"s2\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "\n",
    "def df_to_hf_reg(df: pd.DataFrame):\n",
    "    from datasets import Dataset\n",
    "\n",
    "    ds = Dataset.from_pandas(df[[\"s1\", \"s2\", \"label\"]], preserve_index=False)\n",
    "    ds = ds.map(tokenize_stsb, batched=True).rename_column(\"label\", \"labels\")\n",
    "    cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "    if \"token_type_ids\" in ds.column_names:\n",
    "        cols.insert(2, \"token_type_ids\")\n",
    "    ds.set_format(type=\"torch\", columns=cols)\n",
    "    return ds\n",
    "\n",
    "\n",
    "stsb_train_ds = df_to_hf_reg(stsb_train)\n",
    "stsb_val_ds = df_to_hf_reg(stsb_val)\n",
    "stsb_test_ds = df_to_hf_reg(stsb_test)\n",
    "\n",
    "reg_model = AutoModelForSequenceClassification.from_pretrained(QQP_MODEL_DIR)\n",
    "\n",
    "if hasattr(reg_model, \"classifier\") and isinstance(reg_model.classifier, nn.Linear):\n",
    "    in_features = int(reg_model.classifier.in_features)\n",
    "    reg_model.classifier = nn.Linear(in_features, 1)\n",
    "elif hasattr(reg_model, \"score\") and isinstance(reg_model.score, nn.Linear):\n",
    "    in_features = int(reg_model.score.in_features)\n",
    "    reg_model.score = nn.Linear(in_features, 1)\n",
    "else:\n",
    "    raise RuntimeError(\"Unsupported model head: cannot find Linear classifier or score layer.\")\n",
    "\n",
    "reg_model.config.num_labels = 1\n",
    "reg_model.config.problem_type = \"regression\"\n",
    "\n",
    "\n",
    "def compute_reg_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.asarray(preds).reshape(-1)\n",
    "    labels = np.asarray(labels).reshape(-1)\n",
    "    preds = np.clip(preds, 0.0, 1.0)\n",
    "    return {\n",
    "        \"pearson\": float(pearsonr(labels, preds).statistic),\n",
    "        \"spearman\": float(spearmanr(labels, preds).statistic),\n",
    "    }\n",
    "\n",
    "\n",
    "ta_sig = inspect.signature(TrainingArguments)\n",
    "ta_kwargs = dict(\n",
    "    output_dir=STSB_MODEL_DIR,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=BERT_STSB_NUM_EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=50,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "if \"evaluation_strategy\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"evaluation_strategy\"] = \"epoch\"\n",
    "elif \"eval_strategy\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"eval_strategy\"] = \"epoch\"\n",
    "\n",
    "if \"report_to\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"report_to\"] = \"none\"\n",
    "\n",
    "if \"dataloader_pin_memory\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"dataloader_pin_memory\"] = False\n",
    "\n",
    "if \"use_mps_device\" in ta_sig.parameters:\n",
    "    ta_kwargs[\"use_mps_device\"] = (DEVICE == \"mps\")\n",
    "\n",
    "reg_args = TrainingArguments(**ta_kwargs)\n",
    "\n",
    "tr_sig = inspect.signature(Trainer)\n",
    "reg_trainer_kwargs = dict(\n",
    "    model=reg_model,\n",
    "    args=reg_args,\n",
    "    train_dataset=stsb_train_ds,\n",
    "    eval_dataset=stsb_val_ds,\n",
    "    compute_metrics=compute_reg_metrics,\n",
    ")\n",
    "if \"tokenizer\" in tr_sig.parameters:\n",
    "    reg_trainer_kwargs[\"tokenizer\"] = stsb_tokenizer\n",
    "elif \"processing_class\" in tr_sig.parameters:\n",
    "    reg_trainer_kwargs[\"processing_class\"] = stsb_tokenizer\n",
    "\n",
    "reg_trainer = Trainer(**reg_trainer_kwargs)\n",
    "\n",
    "reg_trainer.train()\n",
    "\n",
    "stsb_eval_val = reg_trainer.evaluate(stsb_val_ds)\n",
    "stsb_eval_test = reg_trainer.evaluate(stsb_test_ds)\n",
    "\n",
    "_val_pred = reg_trainer.predict(stsb_val_ds).predictions.reshape(-1)\n",
    "_test_pred = reg_trainer.predict(stsb_test_ds).predictions.reshape(-1)\n",
    "bert_stsb_val_pred = np.clip(_val_pred, 0.0, 1.0).astype(np.float32)\n",
    "bert_stsb_test_pred = np.clip(_test_pred, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "bert_stsb_metrics = {\n",
    "    \"stsb_val_pearson\": float(stsb_eval_val.get(\"eval_pearson\", np.nan)),\n",
    "    \"stsb_val_spearman\": float(stsb_eval_val.get(\"eval_spearman\", np.nan)),\n",
    "    \"stsb_test_pearson\": float(stsb_eval_test.get(\"eval_pearson\", np.nan)),\n",
    "    \"stsb_test_spearman\": float(stsb_eval_test.get(\"eval_spearman\", np.nan)),\n",
    "}\n",
    "print(\"BERT QQP→STS-B metrics:\", bert_stsb_metrics)\n",
    "\n",
    "reg_trainer.save_model(reg_args.output_dir)\n",
    "stsb_tokenizer.save_pretrained(reg_args.output_dir)\n",
    "print(\"Saved QQP→STS-B regression model to:\", reg_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0acb7b",
   "metadata": {},
   "source": [
    "## 5. 阶段性训练（SBERT）\n",
    "\n",
    "SBERT 使用句向量 + CosineSimilarityLoss 进行 STS-B 回归微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBERT STS-B 微调\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "print(\"SBERT_NUM_EPOCHS:\", SBERT_NUM_EPOCHS)\n",
    "\n",
    "sbert = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=DEVICE)\n",
    "\n",
    "train_examples = [InputExample(texts=[a, b], label=float(y)) for a, b, y in zip(stsb_train[\"s1\"], stsb_train[\"s2\"], stsb_train[\"label\"])]\n",
    "val_examples = [InputExample(texts=[a, b], label=float(y)) for a, b, y in zip(stsb_val[\"s1\"], stsb_val[\"s2\"], stsb_val[\"label\"])]\n",
    "\n",
    "train_loader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "train_loss = losses.CosineSimilarityLoss(model=sbert)\n",
    "\n",
    "warmup_steps = int(0.1 * len(train_loader) * SBERT_NUM_EPOCHS)\n",
    "\n",
    "sbert_output_dir = os.path.join(MODELS_DIR, \"sbert_stsb\")\n",
    "\n",
    "sbert.fit(\n",
    "    train_objectives=[(train_loader, train_loss)],\n",
    "    epochs=SBERT_NUM_EPOCHS,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=sbert_output_dir,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "\n",
    "sbert = SentenceTransformer(sbert_output_dir, device=DEVICE)\n",
    "\n",
    "\n",
    "def sbert_cosine_scores(df: pd.DataFrame) -> np.ndarray:\n",
    "    emb1 = sbert.encode(df[\"s1\"].tolist(), batch_size=64, normalize_embeddings=True, show_progress_bar=False)\n",
    "    emb2 = sbert.encode(df[\"s2\"].tolist(), batch_size=64, normalize_embeddings=True, show_progress_bar=False)\n",
    "    scores = (emb1 * emb2).sum(axis=1)\n",
    "    return ((scores + 1.0) / 2.0).clip(0.0, 1.0).astype(np.float32)\n",
    "\n",
    "\n",
    "sbert_val_pred = sbert_cosine_scores(stsb_val)\n",
    "sbert_test_pred = sbert_cosine_scores(stsb_test)\n",
    "\n",
    "sbert_stsb_metrics = {\n",
    "    \"stsb_val_pearson\": float(pearsonr(stsb_val[\"label\"].values, sbert_val_pred).statistic),\n",
    "    \"stsb_val_spearman\": float(spearmanr(stsb_val[\"label\"].values, sbert_val_pred).statistic),\n",
    "    \"stsb_test_pearson\": float(pearsonr(stsb_test[\"label\"].values, sbert_test_pred).statistic),\n",
    "    \"stsb_test_spearman\": float(spearmanr(stsb_test[\"label\"].values, sbert_test_pred).statistic),\n",
    "}\n",
    "print(\"SBERT STS-B metrics:\", sbert_stsb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8826ccb",
   "metadata": {},
   "source": [
    "## 6. 统一评测与结果汇总\n",
    "\n",
    "从磁盘加载已保存模型，统一在 test 上重算，保证表格可复现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a98c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c3982499f143cfa9e98d6a9d90e58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca72de6ac5e4ef2a58c417ad49cf694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06961c48bd9540a9922ab4e17c3f7832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee25e30c5b054d28a1af7a2298173502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13df5b9eceb438fa8e48be385b1678b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008c3008845a401c8714510bef2706b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bdd9fe8dca43f69fe2765065ab4616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c03efd65495478b89c25b1fb6c0983f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'qqp_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 201\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_row\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, qqp: \u001b[38;5;28mdict\u001b[39m, stsb: \u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    193\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model_name,\n\u001b[32m    194\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mQQP acc (test)\u001b[39m\u001b[33m\"\u001b[39m: qqp.get(\u001b[33m\"\u001b[39m\u001b[33mqqp_test_acc\u001b[39m\u001b[33m\"\u001b[39m, np.nan),\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSTS-B Spearman (test)\u001b[39m\u001b[33m\"\u001b[39m: stsb.get(\u001b[33m\"\u001b[39m\u001b[33mstsb_test_spearman\u001b[39m\u001b[33m\"\u001b[39m, np.nan),\n\u001b[32m    198\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m albert_qqp_zeroshot_metrics = \u001b[38;5;28mnext\u001b[39m((r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[43mqqp_rows\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33malbert-base-v2\u001b[39m\u001b[33m\"\u001b[39m), {})\n\u001b[32m    202\u001b[39m roberta_qqp_zeroshot_metrics = \u001b[38;5;28mnext\u001b[39m((r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m qqp_rows \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mroberta-base\u001b[39m\u001b[33m\"\u001b[39m), {})\n\u001b[32m    205\u001b[39m rows = [\n\u001b[32m    206\u001b[39m     make_row(\u001b[33m\"\u001b[39m\u001b[33mLexical (TF-IDF)\u001b[39m\u001b[33m\"\u001b[39m, _get_metrics(\u001b[33m\"\u001b[39m\u001b[33mlex_qqp_metrics\u001b[39m\u001b[33m\"\u001b[39m), _get_metrics(\u001b[33m\"\u001b[39m\u001b[33mlex_stsb_metrics\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m    207\u001b[39m     make_row(\u001b[33m\"\u001b[39m\u001b[33mStatic Emb (enwiki-50k_100d mean)\u001b[39m\u001b[33m\"\u001b[39m, _get_metrics(\u001b[33m\"\u001b[39m\u001b[33mstatic_qqp_metrics\u001b[39m\u001b[33m\"\u001b[39m), _get_metrics(\u001b[33m\"\u001b[39m\u001b[33mstatic_stsb_metrics\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m   (...)\u001b[39m\u001b[32m    214\u001b[39m     make_row(\u001b[33m\"\u001b[39m\u001b[33mBERT (QQP→STS-B)\u001b[39m\u001b[33m\"\u001b[39m, bert_qqp_metrics_disk, bert_stsb_metrics_disk),\n\u001b[32m    215\u001b[39m ]\n",
      "\u001b[31mNameError\u001b[39m: name 'qqp_rows' is not defined"
     ]
    }
   ],
   "source": [
    "# 统一评测：从磁盘加载模型重算\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "BERT_QQP_DIR = os.path.join(MODELS_DIR, \"bert_qqp\")\n",
    "BERT_STSB_DIRECT_DIR = os.path.join(MODELS_DIR, \"bert_stsb_direct\")\n",
    "BERT_QQP_TO_STSB_DIR = os.path.join(MODELS_DIR, \"bert_qqp_to_stsb_reg\")\n",
    "SBERT_STSB_DIR = os.path.join(MODELS_DIR, \"sbert_stsb\")\n",
    "\n",
    "\n",
    "def _batched_indices(n: int, batch_size: int):\n",
    "    for i in range(0, n, batch_size):\n",
    "        yield i, min(i + batch_size, n)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_bert_qqp_from_dir(model_dir: str, df: pd.DataFrame, batch_size: int = 32) -> dict:\n",
    "    tok = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    y_true = df[\"label\"].values.astype(int)\n",
    "    preds = np.zeros((len(df),), dtype=np.int64)\n",
    "\n",
    "    for i, j in _batched_indices(len(df), batch_size):\n",
    "        batch = df.iloc[i:j]\n",
    "        enc = tok(\n",
    "            batch[\"s1\"].tolist(),\n",
    "            batch[\"s2\"].tolist(),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "        logits = model(**enc).logits\n",
    "        preds[i:j] = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "    return {\n",
    "        \"qqp_test_acc\": float(accuracy_score(y_true, preds)),\n",
    "        \"qqp_test_f1\": float(f1_score(y_true, preds)),\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_bert_stsb_reg_from_dir(model_dir: str, df: pd.DataFrame, batch_size: int = 32) -> dict:\n",
    "    tok = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    y_true = df[\"label\"].values.astype(np.float32)\n",
    "    preds = np.zeros((len(df),), dtype=np.float32)\n",
    "\n",
    "    for i, j in _batched_indices(len(df), batch_size):\n",
    "        batch = df.iloc[i:j]\n",
    "        enc = tok(\n",
    "            batch[\"s1\"].tolist(),\n",
    "            batch[\"s2\"].tolist(),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "        logits = model(**enc).logits\n",
    "        p = logits.detach().cpu().numpy().reshape(-1).astype(np.float32)\n",
    "        preds[i:j] = np.clip(p, 0.0, 1.0)\n",
    "\n",
    "    return {\n",
    "        \"stsb_test_pearson\": float(pearsonr(y_true, preds).statistic),\n",
    "        \"stsb_test_spearman\": float(spearmanr(y_true, preds).statistic),\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def bert_reg_scores(model_dir: str, df: pd.DataFrame, batch_size: int = 32) -> np.ndarray:\n",
    "    tok = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    preds = np.zeros((len(df),), dtype=np.float32)\n",
    "    for i, j in _batched_indices(len(df), batch_size):\n",
    "        batch = df.iloc[i:j]\n",
    "        enc = tok(\n",
    "            batch[\"s1\"].tolist(),\n",
    "            batch[\"s2\"].tolist(),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "        logits = model(**enc).logits\n",
    "        p = logits.detach().cpu().numpy().reshape(-1).astype(np.float32)\n",
    "        preds[i:j] = np.clip(p, 0.0, 1.0)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def eval_reg_as_binary_on_qqp(model_dir: str, val_df: pd.DataFrame, test_df: pd.DataFrame) -> dict:\n",
    "    val_score = bert_reg_scores(model_dir, val_df)\n",
    "    test_score = bert_reg_scores(model_dir, test_df)\n",
    "\n",
    "    thresholds = np.linspace(0.0, 1.0, 101)\n",
    "    best_t = 0.5\n",
    "    best_f1 = -1.0\n",
    "    y_val = val_df[\"label\"].values.astype(int)\n",
    "    for t in thresholds:\n",
    "        pred = (val_score >= t).astype(int)\n",
    "        cur = f1_score(y_val, pred)\n",
    "        if cur > best_f1:\n",
    "            best_f1 = float(cur)\n",
    "            best_t = float(t)\n",
    "\n",
    "    y_test = test_df[\"label\"].values.astype(int)\n",
    "    test_pred = (test_score >= best_t).astype(int)\n",
    "    return {\n",
    "        \"qqp_test_acc\": float(accuracy_score(y_test, test_pred)),\n",
    "        \"qqp_test_f1\": float(f1_score(y_test, test_pred)),\n",
    "        \"threshold\": float(best_t),\n",
    "    }\n",
    "\n",
    "\n",
    "def sbert_scores(model_dir: str, df: pd.DataFrame, batch_size: int = 64) -> np.ndarray:\n",
    "    sbert_eval = SentenceTransformer(model_dir, device=DEVICE)\n",
    "    emb1 = sbert_eval.encode(df[\"s1\"].tolist(), batch_size=batch_size, normalize_embeddings=True, show_progress_bar=False)\n",
    "    emb2 = sbert_eval.encode(df[\"s2\"].tolist(), batch_size=batch_size, normalize_embeddings=True, show_progress_bar=False)\n",
    "    scores = (emb1 * emb2).sum(axis=1)\n",
    "    return ((scores + 1.0) / 2.0).clip(0.0, 1.0).astype(np.float32)\n",
    "\n",
    "\n",
    "def eval_sbert_stsb_from_dir(model_dir: str, df: pd.DataFrame, batch_size: int = 64) -> dict:\n",
    "    preds = sbert_scores(model_dir, df, batch_size=batch_size)\n",
    "    y_true = df[\"label\"].values.astype(np.float32)\n",
    "    return {\n",
    "        \"stsb_test_pearson\": float(pearsonr(y_true, preds).statistic),\n",
    "        \"stsb_test_spearman\": float(spearmanr(y_true, preds).statistic),\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_sbert_as_binary_on_qqp(model_dir: str, val_df: pd.DataFrame, test_df: pd.DataFrame) -> dict:\n",
    "    val_score = sbert_scores(model_dir, val_df)\n",
    "    test_score = sbert_scores(model_dir, test_df)\n",
    "\n",
    "    thresholds = np.linspace(0.0, 1.0, 101)\n",
    "    best_t = 0.5\n",
    "    best_f1 = -1.0\n",
    "    y_val = val_df[\"label\"].values.astype(int)\n",
    "    for t in thresholds:\n",
    "        pred = (val_score >= t).astype(int)\n",
    "        cur = f1_score(y_val, pred)\n",
    "        if cur > best_f1:\n",
    "            best_f1 = float(cur)\n",
    "            best_t = float(t)\n",
    "\n",
    "    y_test = test_df[\"label\"].values.astype(int)\n",
    "    test_pred = (test_score >= best_t).astype(int)\n",
    "    return {\n",
    "        \"qqp_test_acc\": float(accuracy_score(y_test, test_pred)),\n",
    "        \"qqp_test_f1\": float(f1_score(y_test, test_pred)),\n",
    "        \"threshold\": float(best_t),\n",
    "    }\n",
    "\n",
    "\n",
    "bert_qqp_metrics_disk = eval_bert_qqp_from_dir(BERT_QQP_DIR, qqp_test) if os.path.exists(BERT_QQP_DIR) else {}\n",
    "bert_stsb_direct_metrics_disk = eval_bert_stsb_reg_from_dir(BERT_STSB_DIRECT_DIR, stsb_test) if os.path.exists(BERT_STSB_DIRECT_DIR) else {}\n",
    "bert_stsb_metrics_disk = eval_bert_stsb_reg_from_dir(BERT_QQP_TO_STSB_DIR, stsb_test) if os.path.exists(BERT_QQP_TO_STSB_DIR) else {}\n",
    "\n",
    "sbert_stsb_metrics_disk = eval_sbert_stsb_from_dir(SBERT_STSB_DIR, stsb_test) if os.path.exists(SBERT_STSB_DIR) else {}\n",
    "\n",
    "bert_stsb_direct_qqp_metrics = (\n",
    "    eval_reg_as_binary_on_qqp(BERT_STSB_DIRECT_DIR, qqp_val, qqp_test)\n",
    "    if os.path.exists(BERT_STSB_DIRECT_DIR)\n",
    "    else {}\n",
    " )\n",
    "\n",
    "sbert_stsb_qqp_metrics = (\n",
    "    eval_sbert_as_binary_on_qqp(SBERT_STSB_DIR, qqp_val, qqp_test)\n",
    "    if os.path.exists(SBERT_STSB_DIR)\n",
    "    else {}\n",
    " )\n",
    "\n",
    "\n",
    "def _get_metrics(name: str) -> dict:\n",
    "    m = globals().get(name, {})\n",
    "    return m if isinstance(m, dict) else {}\n",
    "\n",
    "\n",
    "def make_row(model_name: str, qqp: dict, stsb: dict) -> dict:\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"QQP acc (test)\": qqp.get(\"qqp_test_acc\", np.nan),\n",
    "        \"QQP F1 (test)\": qqp.get(\"qqp_test_f1\", np.nan),\n",
    "        \"STS-B Pearson (test)\": stsb.get(\"stsb_test_pearson\", np.nan),\n",
    "        \"STS-B Spearman (test)\": stsb.get(\"stsb_test_spearman\", np.nan),\n",
    "    }\n",
    "\n",
    "\n",
    "qqp_rows_local = globals().get(\"qqp_rows\", [])\n",
    "albert_qqp_zeroshot_metrics = next((r for r in qqp_rows_local if r.get(\"model\") == \"albert-base-v2\"), {})\n",
    "roberta_qqp_zeroshot_metrics = next((r for r in qqp_rows_local if r.get(\"model\") == \"roberta-base\"), {})\n",
    "\n",
    "\n",
    "rows = [\n",
    "    make_row(\"Lexical (TF-IDF)\", _get_metrics(\"lex_qqp_metrics\"), _get_metrics(\"lex_stsb_metrics\")),\n",
    "    make_row(\"Static Emb (enwiki-50k_100d mean)\", _get_metrics(\"static_qqp_metrics\"), _get_metrics(\"static_stsb_metrics\")),\n",
    "    make_row(\"BERT base (zero-shot)\", _get_metrics(\"bert_qqp_zeroshot_metrics\"), {}),\n",
    "    make_row(\"ALBERT (zero-shot)\", albert_qqp_zeroshot_metrics, {}),\n",
    "    make_row(\"RoBERTa (zero-shot)\", roberta_qqp_zeroshot_metrics, {}),\n",
    "    make_row(\"SBERT (pretrained)\", _get_metrics(\"sbert_qqp_zeroshot_metrics\"), _get_metrics(\"sbert_stsb_zeroshot_metrics\")),\n",
    "    make_row(\"BERT (STS-B)\", bert_stsb_direct_qqp_metrics, bert_stsb_direct_metrics_disk),\n",
    "    make_row(\"SBERT (STS-B)\", sbert_stsb_qqp_metrics, sbert_stsb_metrics_disk),\n",
    "    make_row(\"BERT (QQP→STS-B)\", bert_qqp_metrics_disk, bert_stsb_metrics_disk),\n",
    "]\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550b2dca",
   "metadata": {},
   "source": [
    "## 7. 鲁棒性分析（Stress Test）\n",
    "\n",
    "构建 8 类语义扰动的 stress-test，dev 选阈值，test 报告 Acc/F1 与分类型准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eeb596b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60f526c7f02424688bf85a265a3857b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbe5003d21b42678338b2b3dfb466e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be9559bf2fd486baa877d0ea1738f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4812b05bf1bc4554b834b34e4d1d0fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary stress test summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>dev_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>pearson</th>\n",
       "      <th>spearman</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT-QQP→STS-B</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.3419</td>\n",
       "      <td>0.3224</td>\n",
       "      <td>0.5068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBERT-STS-B</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.1997</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>0.5275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  threshold  dev_f1  test_acc  test_f1  pearson  spearman  \\\n",
       "0  BERT-QQP→STS-B       0.68     0.8      0.65   0.6316   0.3419    0.3224   \n",
       "1     SBERT-STS-B       0.89     0.8      0.55   0.5714   0.1997    0.2354   \n",
       "\n",
       "      mae  \n",
       "0  0.5068  \n",
       "1  0.5275  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-category accuracy on stress-test test split:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>BERT-QQP→STS-B</th>\n",
       "      <th>SBERT-STS-B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comparative</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direction</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inc_dec</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modal</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negation</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeric</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>role_swap</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model        BERT-QQP→STS-B  SBERT-STS-B\n",
       "cat                                     \n",
       "comparative        0.666667     0.333333\n",
       "direction          1.000000     0.666667\n",
       "inc_dec            0.333333     0.666667\n",
       "modal              1.000000     0.500000\n",
       "negation           0.500000     0.500000\n",
       "numeric            0.666667     0.666667\n",
       "quantifier         1.000000     1.000000\n",
       "role_swap          0.333333     0.333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stress-test: 8 类语义扰动\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "BERT_QQP_STSB_DIR = os.path.join(MODELS_DIR, \"bert_qqp_to_stsb_reg\")\n",
    "SBERT_STSB_DIR = os.path.join(MODELS_DIR, \"sbert_stsb\")\n",
    "\n",
    "stress_pairs = [\n",
    "    # 1) Negation\n",
    "    {\"cat\": \"negation\", \"s1\": \"The product is available.\", \"s2\": \"The product is available.\", \"label\": 1},\n",
    "    {\"cat\": \"negation\", \"s1\": \"The product is available.\", \"s2\": \"The product is not available.\", \"label\": 0},\n",
    "    {\"cat\": \"negation\", \"s1\": \"He likes coffee.\", \"s2\": \"He does not like coffee.\", \"label\": 0},\n",
    "    {\"cat\": \"negation\", \"s1\": \"The service did not fail.\", \"s2\": \"The service was successful.\", \"label\": 1},\n",
    "\n",
    "    # 2) Increase/Decrease\n",
    "    {\"cat\": \"inc_dec\", \"s1\": \"Revenue increased by 10 percent.\", \"s2\": \"Revenue went up by 10 percent.\", \"label\": 1},\n",
    "    {\"cat\": \"inc_dec\", \"s1\": \"Revenue increased by 10 percent.\", \"s2\": \"Revenue decreased by 10 percent.\", \"label\": 0},\n",
    "    {\"cat\": \"inc_dec\", \"s1\": \"The temperature rose rapidly.\", \"s2\": \"The temperature fell rapidly.\", \"label\": 0},\n",
    "    {\"cat\": \"inc_dec\", \"s1\": \"Sales dropped this quarter.\", \"s2\": \"Sales decreased this quarter.\", \"label\": 1},\n",
    "\n",
    "    # 3) Comparative Flip\n",
    "    {\"cat\": \"comparative\", \"s1\": \"This model is more accurate.\", \"s2\": \"This model is less accurate.\", \"label\": 0},\n",
    "    {\"cat\": \"comparative\", \"s1\": \"Version A is better than version B.\", \"s2\": \"Version A outperforms version B.\", \"label\": 1},\n",
    "    {\"cat\": \"comparative\", \"s1\": \"The new phone is cheaper.\", \"s2\": \"The new phone is more expensive.\", \"label\": 0},\n",
    "    {\"cat\": \"comparative\", \"s1\": \"Latency is lower in system X.\", \"s2\": \"System X has lower latency.\", \"label\": 1},\n",
    "\n",
    "    # 4) Role Swap\n",
    "    {\"cat\": \"role_swap\", \"s1\": \"Alice gave Bob the book.\", \"s2\": \"Bob gave Alice the book.\", \"label\": 0},\n",
    "    {\"cat\": \"role_swap\", \"s1\": \"The teacher praised the student.\", \"s2\": \"The student praised the teacher.\", \"label\": 0},\n",
    "    {\"cat\": \"role_swap\", \"s1\": \"The nurse treated the patient.\", \"s2\": \"The patient was treated by the nurse.\", \"label\": 1},\n",
    "    {\"cat\": \"role_swap\", \"s1\": \"Tom helped Jerry.\", \"s2\": \"Jerry was helped by Tom.\", \"label\": 1},\n",
    "\n",
    "    # 5) Numeric Change\n",
    "    {\"cat\": \"numeric\", \"s1\": \"The package weighs 5 kg.\", \"s2\": \"The package weighs 50 kg.\", \"label\": 0},\n",
    "    {\"cat\": \"numeric\", \"s1\": \"The discount is 10 percent.\", \"s2\": \"The discount is 10 percent.\", \"label\": 1},\n",
    "    {\"cat\": \"numeric\", \"s1\": \"The meeting starts at 3 PM.\", \"s2\": \"The meeting starts at 8 PM.\", \"label\": 0},\n",
    "    {\"cat\": \"numeric\", \"s1\": \"The event is in 2024.\", \"s2\": \"The event is in 2023.\", \"label\": 0},\n",
    "\n",
    "    # 6) Quantifier Shift\n",
    "    {\"cat\": \"quantifier\", \"s1\": \"All customers received a refund.\", \"s2\": \"Some customers received a refund.\", \"label\": 0},\n",
    "    {\"cat\": \"quantifier\", \"s1\": \"Every file was uploaded.\", \"s2\": \"All files were uploaded.\", \"label\": 1},\n",
    "    {\"cat\": \"quantifier\", \"s1\": \"None of the users agreed.\", \"s2\": \"Some of the users agreed.\", \"label\": 0},\n",
    "    {\"cat\": \"quantifier\", \"s1\": \"A few students were absent.\", \"s2\": \"Some students were absent.\", \"label\": 1},\n",
    "\n",
    "    # 7) Modal Shift\n",
    "    {\"cat\": \"modal\", \"s1\": \"Users must reset their password.\", \"s2\": \"Users may reset their password.\", \"label\": 0},\n",
    "    {\"cat\": \"modal\", \"s1\": \"You should back up the data.\", \"s2\": \"You ought to back up the data.\", \"label\": 1},\n",
    "    {\"cat\": \"modal\", \"s1\": \"Access is required to enter.\", \"s2\": \"Access is optional to enter.\", \"label\": 0},\n",
    "    {\"cat\": \"modal\", \"s1\": \"Visitors are allowed to park here.\", \"s2\": \"Visitors may park here.\", \"label\": 1},\n",
    "\n",
    "    # 8) Direction Swap\n",
    "    {\"cat\": \"direction\", \"s1\": \"Flights from Paris to London are delayed.\", \"s2\": \"Flights from London to Paris are delayed.\", \"label\": 0},\n",
    "    {\"cat\": \"direction\", \"s1\": \"The train goes from A to B.\", \"s2\": \"The train goes from B to A.\", \"label\": 0},\n",
    "    {\"cat\": \"direction\", \"s1\": \"The package moved from room A to room B.\", \"s2\": \"The package moved from room A to room B.\", \"label\": 1},\n",
    "    {\"cat\": \"direction\", \"s1\": \"Water flows from the tank to the pipe.\", \"s2\": \"Water goes from the tank into the pipe.\", \"label\": 1},\n",
    "]\n",
    "\n",
    "stress_df = pd.DataFrame(stress_pairs)\n",
    "\n",
    "\n",
    "def pick_best_threshold(y_true: np.ndarray, y_score: np.ndarray) -> tuple[float, float]:\n",
    "    ts = np.linspace(0.0, 1.0, 101)\n",
    "    best_t, best_f1 = 0.5, -1.0\n",
    "    for t in ts:\n",
    "        pred = (y_score >= t).astype(int)\n",
    "        cur = f1_score(y_true, pred)\n",
    "        if cur > best_f1:\n",
    "            best_f1 = float(cur)\n",
    "            best_t = float(t)\n",
    "    return best_t, best_f1\n",
    "\n",
    "\n",
    "def eval_binary(y_true: np.ndarray, y_score: np.ndarray, t: float) -> dict:\n",
    "    pred = (y_score >= t).astype(int)\n",
    "    return {\n",
    "        \"acc\": float(accuracy_score(y_true, pred)),\n",
    "        \"f1\": float(f1_score(y_true, pred)),\n",
    "    }\n",
    "\n",
    "\n",
    "def corr_pack(y_true: np.ndarray, y_score: np.ndarray) -> dict:\n",
    "    return {\n",
    "        \"pearson\": float(pearsonr(y_true, y_score).statistic),\n",
    "        \"spearman\": float(spearmanr(y_true, y_score).statistic),\n",
    "        \"mae\": float(np.mean(np.abs(y_true - y_score))),\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def bert_similarity_scores(model_dir: str, df: pd.DataFrame, batch_size: int = 16) -> np.ndarray:\n",
    "    tok = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    out = np.zeros((len(df),), dtype=np.float32)\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        j = min(i + batch_size, len(df))\n",
    "        batch = df.iloc[i:j]\n",
    "        enc = tok(\n",
    "            batch[\"s1\"].tolist(),\n",
    "            batch[\"s2\"].tolist(),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "        logits = model(**enc).logits\n",
    "        if logits.shape[-1] == 1:\n",
    "            score = torch.sigmoid(logits).reshape(-1)\n",
    "        else:\n",
    "            score = torch.softmax(logits, dim=-1)[:, 1]\n",
    "        out[i:j] = torch.clamp(score, 0.0, 1.0).detach().cpu().numpy()\n",
    "    return out\n",
    "\n",
    "\n",
    "def sbert_similarity_scores(model_dir: str, df: pd.DataFrame, batch_size: int = 32) -> np.ndarray:\n",
    "    sbert_eval = SentenceTransformer(model_dir, device=DEVICE)\n",
    "    emb1 = sbert_eval.encode(df[\"s1\"].tolist(), batch_size=batch_size, normalize_embeddings=True, show_progress_bar=False)\n",
    "    emb2 = sbert_eval.encode(df[\"s2\"].tolist(), batch_size=batch_size, normalize_embeddings=True, show_progress_bar=False)\n",
    "    cosine = (emb1 * emb2).sum(axis=1)\n",
    "    return ((cosine + 1.0) / 2.0).clip(0.0, 1.0).astype(np.float32)\n",
    "\n",
    "\n",
    "dev_df, test_df = train_test_split(\n",
    "    stress_df,\n",
    "    test_size=0.6,\n",
    "    random_state=SEED,\n",
    "    stratify=stress_df[\"label\"],\n",
    ")\n",
    "\n",
    "y_dev = dev_df[\"label\"].values.astype(int)\n",
    "y_test = test_df[\"label\"].values.astype(int)\n",
    "\n",
    "rows = []\n",
    "per_cat_tables = []\n",
    "\n",
    "if os.path.exists(BERT_QQP_STSB_DIR):\n",
    "    bert_dev_score = bert_similarity_scores(BERT_QQP_STSB_DIR, dev_df)\n",
    "    bert_test_score = bert_similarity_scores(BERT_QQP_STSB_DIR, test_df)\n",
    "    bert_t, bert_dev_f1 = pick_best_threshold(y_dev, bert_dev_score)\n",
    "    bert_test_metrics = eval_binary(y_test, bert_test_score, bert_t)\n",
    "    bert_corr = corr_pack(y_test.astype(np.float32), bert_test_score)\n",
    "    rows.append({\n",
    "        \"model\": \"BERT-QQP→STS-B\",\n",
    "        \"threshold\": round(bert_t, 3),\n",
    "        \"dev_f1\": round(bert_dev_f1, 4),\n",
    "        \"test_acc\": round(bert_test_metrics[\"acc\"], 4),\n",
    "        \"test_f1\": round(bert_test_metrics[\"f1\"], 4),\n",
    "        \"pearson\": round(bert_corr[\"pearson\"], 4),\n",
    "        \"spearman\": round(bert_corr[\"spearman\"], 4),\n",
    "        \"mae\": round(bert_corr[\"mae\"], 4),\n",
    "    })\n",
    "    tmp = test_df.copy()\n",
    "    tmp[\"pred\"] = (bert_test_score >= bert_t).astype(int)\n",
    "    tmp[\"ok\"] = (tmp[\"pred\"] == tmp[\"label\"]).astype(int)\n",
    "    per_cat = tmp.groupby(\"cat\", as_index=False)[\"ok\"].mean().rename(columns={\"ok\": \"acc\"})\n",
    "    per_cat[\"model\"] = \"BERT-QQP→STS-B\"\n",
    "    per_cat_tables.append(per_cat)\n",
    "else:\n",
    "    print(\"WARN: missing dir\", BERT_QQP_STSB_DIR)\n",
    "\n",
    "if os.path.exists(SBERT_STSB_DIR):\n",
    "    sbert_dev_score = sbert_similarity_scores(SBERT_STSB_DIR, dev_df)\n",
    "    sbert_test_score = sbert_similarity_scores(SBERT_STSB_DIR, test_df)\n",
    "    sbert_t, sbert_dev_f1 = pick_best_threshold(y_dev, sbert_dev_score)\n",
    "    sbert_test_metrics = eval_binary(y_test, sbert_test_score, sbert_t)\n",
    "    sbert_corr = corr_pack(y_test.astype(np.float32), sbert_test_score)\n",
    "    rows.append({\n",
    "        \"model\": \"SBERT-STS-B\",\n",
    "        \"threshold\": round(sbert_t, 3),\n",
    "        \"dev_f1\": round(sbert_dev_f1, 4),\n",
    "        \"test_acc\": round(sbert_test_metrics[\"acc\"], 4),\n",
    "        \"test_f1\": round(sbert_test_metrics[\"f1\"], 4),\n",
    "        \"pearson\": round(sbert_corr[\"pearson\"], 4),\n",
    "        \"spearman\": round(sbert_corr[\"spearman\"], 4),\n",
    "        \"mae\": round(sbert_corr[\"mae\"], 4),\n",
    "    })\n",
    "    tmp = test_df.copy()\n",
    "    tmp[\"pred\"] = (sbert_test_score >= sbert_t).astype(int)\n",
    "    tmp[\"ok\"] = (tmp[\"pred\"] == tmp[\"label\"]).astype(int)\n",
    "    per_cat = tmp.groupby(\"cat\", as_index=False)[\"ok\"].mean().rename(columns={\"ok\": \"acc\"})\n",
    "    per_cat[\"model\"] = \"SBERT-STS-B\"\n",
    "    per_cat_tables.append(per_cat)\n",
    "else:\n",
    "    print(\"WARN: missing dir\", SBERT_STSB_DIR)\n",
    "\n",
    "if len(rows) == 0:\n",
    "    print(\"没有可用模型可比较，请先确保 bert_qqp_to_stsb_reg 与 sbert_stsb 存在。\")\n",
    "else:\n",
    "    result_df = pd.DataFrame(rows).sort_values([\"pearson\", \"spearman\", \"mae\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "    print(\"Binary stress test summary:\")\n",
    "    display(result_df)\n",
    "\n",
    "    cat_df = pd.concat(per_cat_tables, ignore_index=True)\n",
    "    print(\"Per-category accuracy on stress-test test split:\")\n",
    "    display(cat_df.pivot(index=\"cat\", columns=\"model\", values=\"acc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a7a7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stress-test predictions (test split):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>label</th>\n",
       "      <th>bert_score</th>\n",
       "      <th>bert_pred</th>\n",
       "      <th>sbert_score</th>\n",
       "      <th>sbert_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negation</td>\n",
       "      <td>The product is available.</td>\n",
       "      <td>The product is available.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6918</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negation</td>\n",
       "      <td>The service did not fail.</td>\n",
       "      <td>The service was successful.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6442</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>inc_dec</td>\n",
       "      <td>Revenue increased by 10 percent.</td>\n",
       "      <td>Revenue decreased by 10 percent.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>inc_dec</td>\n",
       "      <td>The temperature rose rapidly.</td>\n",
       "      <td>The temperature fell rapidly.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6136</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>inc_dec</td>\n",
       "      <td>Sales dropped this quarter.</td>\n",
       "      <td>Sales decreased this quarter.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>comparative</td>\n",
       "      <td>This model is more accurate.</td>\n",
       "      <td>This model is less accurate.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comparative</td>\n",
       "      <td>Version A is better than version B.</td>\n",
       "      <td>Version A outperforms version B.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>comparative</td>\n",
       "      <td>Latency is lower in system X.</td>\n",
       "      <td>System X has lower latency.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7116</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>role_swap</td>\n",
       "      <td>Alice gave Bob the book.</td>\n",
       "      <td>Bob gave Alice the book.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>role_swap</td>\n",
       "      <td>The teacher praised the student.</td>\n",
       "      <td>The student praised the teacher.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7131</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>role_swap</td>\n",
       "      <td>Tom helped Jerry.</td>\n",
       "      <td>Jerry was helped by Tom.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>numeric</td>\n",
       "      <td>The package weighs 5 kg.</td>\n",
       "      <td>The package weighs 50 kg.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>numeric</td>\n",
       "      <td>The meeting starts at 3 PM.</td>\n",
       "      <td>The meeting starts at 8 PM.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>numeric</td>\n",
       "      <td>The event is in 2024.</td>\n",
       "      <td>The event is in 2023.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>quantifier</td>\n",
       "      <td>None of the users agreed.</td>\n",
       "      <td>Some of the users agreed.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6350</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>modal</td>\n",
       "      <td>Users must reset their password.</td>\n",
       "      <td>Users may reset their password.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>modal</td>\n",
       "      <td>You should back up the data.</td>\n",
       "      <td>You ought to back up the data.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>direction</td>\n",
       "      <td>The train goes from A to B.</td>\n",
       "      <td>The train goes from B to A.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>direction</td>\n",
       "      <td>The package moved from room A to room B.</td>\n",
       "      <td>The package moved from room A to room B.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>direction</td>\n",
       "      <td>Water flows from the tank to the pipe.</td>\n",
       "      <td>Water goes from the tank into the pipe.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7053</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cat                                        s1  \\\n",
       "0      negation                 The product is available.   \n",
       "3      negation                 The service did not fail.   \n",
       "5       inc_dec          Revenue increased by 10 percent.   \n",
       "6       inc_dec             The temperature rose rapidly.   \n",
       "7       inc_dec               Sales dropped this quarter.   \n",
       "8   comparative              This model is more accurate.   \n",
       "9   comparative       Version A is better than version B.   \n",
       "11  comparative             Latency is lower in system X.   \n",
       "12    role_swap                  Alice gave Bob the book.   \n",
       "13    role_swap          The teacher praised the student.   \n",
       "15    role_swap                         Tom helped Jerry.   \n",
       "16      numeric                  The package weighs 5 kg.   \n",
       "18      numeric               The meeting starts at 3 PM.   \n",
       "19      numeric                     The event is in 2024.   \n",
       "22   quantifier                 None of the users agreed.   \n",
       "24        modal          Users must reset their password.   \n",
       "25        modal              You should back up the data.   \n",
       "29    direction               The train goes from A to B.   \n",
       "30    direction  The package moved from room A to room B.   \n",
       "31    direction    Water flows from the tank to the pipe.   \n",
       "\n",
       "                                          s2  label  bert_score  bert_pred  \\\n",
       "0                  The product is available.      1      0.6918          1   \n",
       "3                The service was successful.      1      0.6442          0   \n",
       "5           Revenue decreased by 10 percent.      0      0.6917          1   \n",
       "6              The temperature fell rapidly.      0      0.6136          0   \n",
       "7              Sales decreased this quarter.      1      0.6786          0   \n",
       "8               This model is less accurate.      0      0.6720          0   \n",
       "9           Version A outperforms version B.      1      0.6570          0   \n",
       "11               System X has lower latency.      1      0.7116          1   \n",
       "12                  Bob gave Alice the book.      0      0.7108          1   \n",
       "13          The student praised the teacher.      0      0.7131          1   \n",
       "15                  Jerry was helped by Tom.      1      0.7056          1   \n",
       "16                 The package weighs 50 kg.      0      0.6541          0   \n",
       "18               The meeting starts at 8 PM.      0      0.6054          0   \n",
       "19                     The event is in 2023.      0      0.6853          1   \n",
       "22                 Some of the users agreed.      0      0.6350          0   \n",
       "24           Users may reset their password.      0      0.6790          0   \n",
       "25            You ought to back up the data.      1      0.7124          1   \n",
       "29               The train goes from B to A.      0      0.6696          0   \n",
       "30  The package moved from room A to room B.      1      0.6864          1   \n",
       "31   Water goes from the tank into the pipe.      1      0.7053          1   \n",
       "\n",
       "    sbert_score  sbert_pred  \n",
       "0        1.0000           1  \n",
       "3        0.7565           0  \n",
       "5        0.8741           0  \n",
       "6        0.8339           0  \n",
       "7        0.8882           0  \n",
       "8        0.9304           1  \n",
       "9        0.8689           0  \n",
       "11       0.9867           1  \n",
       "12       0.9955           1  \n",
       "13       0.9957           1  \n",
       "15       0.9844           1  \n",
       "16       0.8420           0  \n",
       "18       0.8143           0  \n",
       "19       0.9086           1  \n",
       "22       0.8460           0  \n",
       "24       0.9469           1  \n",
       "25       0.9841           1  \n",
       "29       0.9962           1  \n",
       "30       1.0000           1  \n",
       "31       0.9654           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stress-test 预测结果明细（test split）\n",
    "\n",
    "if \"test_df\" not in globals():\n",
    "    raise RuntimeError(\"Stress-test not prepared. Run the stress-test cell first.\")\n",
    "\n",
    "pred_df = test_df.copy()\n",
    "\n",
    "if \"bert_test_score\" not in globals() and os.path.exists(BERT_QQP_STSB_DIR):\n",
    "    bert_test_score = bert_similarity_scores(BERT_QQP_STSB_DIR, test_df)\n",
    "\n",
    "if \"sbert_test_score\" not in globals() and os.path.exists(SBERT_STSB_DIR):\n",
    "    sbert_test_score = sbert_similarity_scores(SBERT_STSB_DIR, test_df)\n",
    "\n",
    "if \"bert_t\" not in globals() and \"bert_test_score\" in globals():\n",
    "    bert_t, _ = pick_best_threshold(y_dev, bert_dev_score)\n",
    "\n",
    "if \"sbert_t\" not in globals() and \"sbert_test_score\" in globals():\n",
    "    sbert_t, _ = pick_best_threshold(y_dev, sbert_dev_score)\n",
    "\n",
    "if \"bert_test_score\" in globals() and \"bert_t\" in globals():\n",
    "    pred_df[\"bert_score\"] = np.round(bert_test_score, 4)\n",
    "    pred_df[\"bert_pred\"] = (bert_test_score >= bert_t).astype(int)\n",
    "\n",
    "if \"sbert_test_score\" in globals() and \"sbert_t\" in globals():\n",
    "    pred_df[\"sbert_score\"] = np.round(sbert_test_score, 4)\n",
    "    pred_df[\"sbert_pred\"] = (sbert_test_score >= sbert_t).astype(int)\n",
    "    pred_df = pred_df.sort_index()\n",
    "print(\"Stress-test predictions (test split):\")\n",
    "display(pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2586bf83",
   "metadata": {},
   "source": [
    "### 7.1 错误案例分析（高词面重叠但语义冲突）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b83b055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0853402adc8e44b9bd61c005b8b83bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard samples for Lexical TF-IDF cosine:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>abs_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>i don t want a president who cares</td>\n",
       "      <td>i don t want a president who is charasmatic</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.985769</td>\n",
       "      <td>0.785769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>a man is tying his shoe</td>\n",
       "      <td>a man ties his shoe</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.260872</td>\n",
       "      <td>0.739128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>a woman is slicing a leek</td>\n",
       "      <td>a woman is slicing ginger</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>india ink image of the day january 27</td>\n",
       "      <td>india ink image of the day march 20</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.815552</td>\n",
       "      <td>0.615552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oscar pistorius sentenced to 5 years in prison</td>\n",
       "      <td>bookkeeper of auschwitz sentenced to four years in prison</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.856633</td>\n",
       "      <td>0.856633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>a band is performing on a stage</td>\n",
       "      <td>a band is playing onstage</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.055266</td>\n",
       "      <td>0.944734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>a man is playing the drums</td>\n",
       "      <td>a man plays the drum</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.092896</td>\n",
       "      <td>0.907104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hrithik roshan wife sussanne part ways</td>\n",
       "      <td>hrithik roshan sussanne to divorce</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 s1  \\\n",
       "38               i don t want a president who cares   \n",
       "331                         a man is tying his shoe   \n",
       "193                       a woman is slicing a leek   \n",
       "325           india ink image of the day january 27   \n",
       "12   oscar pistorius sentenced to 5 years in prison   \n",
       "216                 a band is performing on a stage   \n",
       "119                      a man is playing the drums   \n",
       "30           hrithik roshan wife sussanne part ways   \n",
       "\n",
       "                                                            s2   jaccard  \\\n",
       "38                 i don t want a president who is charasmatic  0.700000   \n",
       "331                                        a man ties his shoe  0.571429   \n",
       "193                                  a woman is slicing ginger  0.666667   \n",
       "325                        india ink image of the day march 20  0.600000   \n",
       "12   bookkeeper of auschwitz sentenced to four years in prison  0.416667   \n",
       "216                                  a band is playing onstage  0.375000   \n",
       "119                                       a man plays the drum  0.375000   \n",
       "30                          hrithik roshan sussanne to divorce  0.375000   \n",
       "\n",
       "     y_true    y_pred   abs_err  \n",
       "38     0.20  0.985769  0.785769  \n",
       "331    1.00  0.260872  0.739128  \n",
       "193    0.44  1.000000  0.560000  \n",
       "325    0.20  0.815552  0.615552  \n",
       "12     0.00  0.856633  0.856633  \n",
       "216    1.00  0.055266  0.944734  \n",
       "119    1.00  0.092896  0.907104  \n",
       "30     0.88  0.000000  0.880000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard samples for SBERT:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>abs_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>i don t want a president who cares</td>\n",
       "      <td>i don t want a president who is charasmatic</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.836500</td>\n",
       "      <td>0.636500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>india ink image of the day january 27</td>\n",
       "      <td>india ink image of the day march 20</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.828340</td>\n",
       "      <td>0.628340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>a woman is writing</td>\n",
       "      <td>a woman is swimming</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.677090</td>\n",
       "      <td>0.577090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the note s must reads for friday may 24 2013</td>\n",
       "      <td>the note s must reads for tuesday october 29 2013</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.944518</td>\n",
       "      <td>0.544518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oscar pistorius sentenced to 5 years in prison</td>\n",
       "      <td>bookkeeper of auschwitz sentenced to four years in prison</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.696947</td>\n",
       "      <td>0.696947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>a cat is playing</td>\n",
       "      <td>a woman is playing flute</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.630331</td>\n",
       "      <td>0.580331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>a man is running on the road</td>\n",
       "      <td>a panda dog is running on the road</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>0.768279</td>\n",
       "      <td>0.434879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>a woman is laying down on the floor and holding a baby up above her</td>\n",
       "      <td>a man is laying on the floor holding a baby up above him</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.903722</td>\n",
       "      <td>0.463722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      s1  \\\n",
       "38                                    i don t want a president who cares   \n",
       "325                                india ink image of the day january 27   \n",
       "275                                                   a woman is writing   \n",
       "4                           the note s must reads for friday may 24 2013   \n",
       "12                        oscar pistorius sentenced to 5 years in prison   \n",
       "297                                                     a cat is playing   \n",
       "250                                         a man is running on the road   \n",
       "126  a woman is laying down on the floor and holding a baby up above her   \n",
       "\n",
       "                                                            s2   jaccard  \\\n",
       "38                 i don t want a president who is charasmatic  0.700000   \n",
       "325                        india ink image of the day march 20  0.600000   \n",
       "275                                        a woman is swimming  0.600000   \n",
       "4            the note s must reads for tuesday october 29 2013  0.538462   \n",
       "12   bookkeeper of auschwitz sentenced to four years in prison  0.416667   \n",
       "297                                   a woman is playing flute  0.500000   \n",
       "250                         a panda dog is running on the road  0.666667   \n",
       "126   a man is laying on the floor holding a baby up above him  0.625000   \n",
       "\n",
       "     y_true    y_pred   abs_err  \n",
       "38   0.2000  0.836500  0.636500  \n",
       "325  0.2000  0.828340  0.628340  \n",
       "275  0.1000  0.677090  0.577090  \n",
       "4    0.4000  0.944518  0.544518  \n",
       "12   0.0000  0.696947  0.696947  \n",
       "297  0.0500  0.630331  0.580331  \n",
       "250  0.3334  0.768279  0.434879  \n",
       "126  0.4400  0.903722  0.463722  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 错误分析：高词面重合但语义差/相反\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "if \"SBERT_STSB_DIR\" not in globals():\n",
    "    SBERT_STSB_DIR = os.path.join(MODELS_DIR, \"sbert_stsb\")\n",
    "\n",
    "\n",
    "def jaccard(a: str, b: str) -> float:\n",
    "    sa = set(a.split())\n",
    "    sb = set(b.split())\n",
    "    if not sa and not sb:\n",
    "        return 1.0\n",
    "    if not sa or not sb:\n",
    "        return 0.0\n",
    "    return len(sa & sb) / len(sa | sb)\n",
    "\n",
    "\n",
    "def hard_samples_stsb(df: pd.DataFrame, pred: np.ndarray, top_k: int = 10):\n",
    "    overlaps = np.array([jaccard(x, y) for x, y in zip(df[\"s1\"], df[\"s2\"])], dtype=np.float32)\n",
    "    y = df[\"label\"].values.astype(np.float32)\n",
    "    err = np.abs(pred.astype(np.float32) - y)\n",
    "    score = overlaps * err\n",
    "    idx = np.argsort(-score)[:top_k]\n",
    "    return df.iloc[idx].assign(jaccard=overlaps[idx], y_true=y[idx], y_pred=pred[idx], abs_err=err[idx])\n",
    "\n",
    "\n",
    "if \"sbert_test_pred\" not in globals() and os.path.exists(SBERT_STSB_DIR):\n",
    "    sbert_eval = SentenceTransformer(SBERT_STSB_DIR, device=DEVICE)\n",
    "    emb1 = sbert_eval.encode(stsb_test[\"s1\"].tolist(), batch_size=64, normalize_embeddings=True, show_progress_bar=False)\n",
    "    emb2 = sbert_eval.encode(stsb_test[\"s2\"].tolist(), batch_size=64, normalize_embeddings=True, show_progress_bar=False)\n",
    "    scores = (emb1 * emb2).sum(axis=1)\n",
    "    sbert_test_pred = ((scores + 1.0) / 2.0).clip(0.0, 1.0).astype(np.float32)\n",
    "\n",
    "if \"lex_stsb_test_pred\" in globals():\n",
    "    hard_lex = hard_samples_stsb(stsb_test, lex_stsb_test_pred, top_k=8)\n",
    "    print(\"Hard samples for Lexical TF-IDF cosine:\")\n",
    "    display(hard_lex[[\"s1\", \"s2\", \"jaccard\", \"y_true\", \"y_pred\", \"abs_err\"]])\n",
    "else:\n",
    "    print(\"Skipping lexical hard samples (baseline not computed).\")\n",
    "\n",
    "if \"sbert_test_pred\" in globals():\n",
    "    hard_sbert = hard_samples_stsb(stsb_test, sbert_test_pred, top_k=8)\n",
    "    print(\"Hard samples for SBERT:\")\n",
    "    display(hard_sbert[[\"s1\", \"s2\", \"jaccard\", \"y_true\", \"y_pred\", \"abs_err\"]])\n",
    "else:\n",
    "    print(\"Skipping SBERT hard samples (SBERT not computed).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f7771",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
